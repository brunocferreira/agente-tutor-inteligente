# --- File: utils_file.py --- #

# --- Libraries --- #
import streamlit as st  # Framework para criar interfaces web interativas.
import os  # Biblioteca para manipula√ß√£o de arquivos e vari√°veis de ambiente.
import re  # Biblioteca para express√µes regulares.
# Biblioteca para serializa√ß√£o e desserializa√ß√£o de objetos Python.
import pickle
import json  # Biblioteca para manipula√ß√£o de arquivos JSON.
import requests  # Biblioteca para fazer requisi√ß√µes HTTP.
import pydub  # Biblioteca para manipula√ß√£o de arquivos de √°udio.

# Remove acentos e caracteres especiais de strings.
from unidecode import unidecode
from pathlib import Path  # Manipula√ß√£o de caminhos de arquivos e diret√≥rios.

# Bibliotecas do LangChain para processamento de linguagem natural e recupera√ß√£o de documentos.
# Implementa√ß√£o de um fluxo de recupera√ß√£o conversacional de informa√ß√µes.
from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain
# Armazena o hist√≥rico da conversa para ser reutilizado durante a intera√ß√£o.
from langchain.memory import ConversationBufferMemory
# Permite a cria√ß√£o de templates para estruturar prompts usados nos modelos de IA.
from langchain.prompts import PromptTemplate
# Carrega e processa documentos PDF para serem utilizados na recupera√ß√£o de informa√ß√µes.
from langchain_community.document_loaders.pdf import PyPDFLoader
# Utiliza a biblioteca FAISS para armazenar e recuperar embeddings de documentos.
from langchain_community.vectorstores.faiss import FAISS
# Divide textos longos em segmentos menores de maneira recursiva para otimizar a recupera√ß√£o de informa√ß√µes.
from langchain_text_splitters import RecursiveCharacterTextSplitter
# Gera embeddings de texto usando modelos da OpenAI.
from langchain_openai.embeddings import OpenAIEmbeddings
# Implementa um modelo de chat baseado na OpenAI para gera√ß√£o de respostas contextuais.
from langchain_openai.chat_models import ChatOpenAI

# Biblioteca para carregar vari√°veis de ambiente do arquivo .env.
from dotenv import load_dotenv, find_dotenv
from configs import *  # Importa configura√ß√µes do sistema.
from assets import *  # Importa estilos e scripts auxiliares.
from moviepy import *  # Biblioteca para manipula√ß√£o de v√≠deos.
# Importa fun√ß√µes auxiliares para integra√ß√£o com OpenAI.
from utils_openai import *
from io import BytesIO  # Biblioteca para manipula√ß√£o de fluxos de bytes.

# --- Environment Setup --- #
# Carrega o arquivo .env que cont√©m as credenciais sens√≠veis.
_ = load_dotenv(find_dotenv())

# Obt√©m a chave da API da OpenAI.
api_key = os.getenv("OPENAI_API_KEY")


# --- Directory Setup --- #
PASTA_CONFIGERACOES = Path(__file__).parent / 'configuracoes'
PASTA_CONFIGERACOES.mkdir(exist_ok=True)
PASTA_MENSAGENS = Path(__file__).parent / 'mensagens'
PASTA_MENSAGENS.mkdir(exist_ok=True)
PASTA_ARQUIVOS = Path(__file__).parent / 'arquivos'
PASTA_ARQUIVOS.mkdir(exist_ok=True)
PASTA_TEMP = Path(__file__).parent / 'temp'
PASTA_TEMP.mkdir(exist_ok=True)

# Arquivos tempor√°rios
ARQUIVO_AUDIO_TEMP = PASTA_TEMP / 'audio.mp3'
ARQUIVO_MIC_TEMP = PASTA_TEMP / 'mic.mp3'
ARQUIVO_VIDEO_TEMP = PASTA_TEMP / 'video.mp4'
ARQUIVO_FOTO_TEMP = PASTA_TEMP / 'foto.jpeg'

# Cache para otimizar convers√µes
CACHE_DESCONVERTE = {}


# --- Methods --- #
# SALVAMENTO E LEITURA DE CONVERSAS ========================

def converte_nome_mensagem(nome_mensagem: str) -> str:
    """
    Converte o nome da mensagem para um formato adequado para uso como nome de arquivo.

    Par√¢metros:
    \n\t`nome_mensagem (str)`: O nome da mensagem a ser convertido.

    Retorno:
    \n\t`str`: Nome da mensagem convertido, sem acentos e caracteres especiais, em min√∫sculas.
    """
    nome_arquivo = unidecode(nome_mensagem)
    nome_arquivo = re.sub(r'\W+', '', nome_arquivo).lower()
    return nome_arquivo


def desconverte_nome_mensagem(nome_arquivo: str) -> str:
    """
    Obt√©m o nome original da mensagem a partir do nome do arquivo.

    Par√¢metros:
    \n\t`nome_arquivo (str)`: O nome do arquivo.

    Retorno:
    \n\t`str`: Nome original associado ao arquivo.
    """
    if not nome_arquivo in CACHE_DESCONVERTE:
        nome_mensagem = ler_mensagem_por_nome_arquivo(
            nome_arquivo, key='nome_mensagem')
        CACHE_DESCONVERTE[nome_arquivo] = nome_mensagem
    return CACHE_DESCONVERTE[nome_arquivo]


def retorna_nome_da_mensagem(mensagens: list) -> str:
    """
    Retorna o nome da mensagem com base na primeira mensagem enviada pelo usu√°rio.

    Par√¢metros:
    \n\t`mensagens (list)`: Lista de mensagens contendo dicion√°rios com chaves 'role' e 'content'.

    Retorno:
    \n\t`str`: Conte√∫do da primeira mensagem do usu√°rio, limitado aos primeiros 30 caracteres.

    Exemplo:
    >>> mensagens = [{"role": "user", "content": "Este √© um exemplo de mensagem longa."}]
    >>> retorna_nome_da_mensagem(mensagens)
    "Este √© um exemplo de mensagem longa."
    """
    nome_mensagem = ''
    for mensagem in mensagens:
        if mensagem['role'] == 'user':
            nome_mensagem = mensagem['content'][:30]
            break
    return nome_mensagem


def salvar_mensagens(mensagens: list) -> bool:
    """
    Salva uma lista de mensagens em um arquivo utilizando `pickle`.

    Par√¢metros:
    \n\t`mensagens (list)`: Lista de mensagens contendo dicion√°rios com chaves 'role' e 'content'.

    Retorno:
    \n\t`bool`: Retorna `False` se a lista de mensagens estiver vazia; caso contr√°rio, salva e retorna `True`.

    Exemplo:
    >>> mensagens = [{"role": "user", "content": "Ol√°!"}]
    >>> salvar_mensagens(mensagens)
    True
    """
    if len(mensagens) == 0:
        return False
    nome_mensagem = retorna_nome_da_mensagem(mensagens)
    nome_arquivo = converte_nome_mensagem(nome_mensagem)
    arquivo_salvar = {
        'nome_mensagem': nome_mensagem,
        'nome_arquivo': nome_arquivo,
        'mensagem': mensagens
    }
    with open(PASTA_MENSAGENS / nome_arquivo, 'wb') as f:
        pickle.dump(arquivo_salvar, f)
    return True


def ler_mensagem_por_nome_arquivo(nome_arquivo: str, key: str = 'mensagem'):
    """
    L√™ uma mensagem salva a partir do nome do arquivo.

    Par√¢metros:
    \n\t`nome_arquivo (str)`: Nome do arquivo contendo a mensagem salva.
    \n\t`key (str)`: Chave espec√≠fica dentro do dicion√°rio salvo para ser retornada (padr√£o: 'mensagem').

    Retorno:
    \n\t`dict | str`: Conte√∫do correspondente √† chave especificada dentro do arquivo salvo.

    Exemplo:
    >>> ler_mensagem_por_nome_arquivo('exemplo_mensagem')
    [{"role": "user", "content": "Ol√°!"}]
    """
    with open(PASTA_MENSAGENS / nome_arquivo, 'rb') as f:
        mensagens = pickle.load(f)
    return mensagens[key]


def ler_mensagens(mensagens: list, key: str = 'mensagem') -> list:
    """
    L√™ mensagens a partir de uma lista fornecida, recuperando os dados armazenados em arquivos.

    Par√¢metros:
    \n\t`mensagens (list)`: Lista contendo mensagens em formato de dicion√°rio com as chaves 'role' e 'content'.
    \n\t`key (str)`: Chave do dicion√°rio armazenado para retornar a informa√ß√£o desejada (padr√£o: 'mensagem').

    Retorno:
    \n\t`list`: Lista de mensagens lidas do arquivo correspondente ou uma lista vazia se nenhum dado for encontrado.

    Exemplo:
    >>> mensagens = [{"role": "user", "content": "Ol√°!"}]
    >>> ler_mensagens(mensagens)
    [{"role": "user", "content": "Ol√°!"}]
    """
    if len(mensagens) == 0:
        return []
    nome_mensagem = retorna_nome_da_mensagem(mensagens)
    nome_arquivo = converte_nome_mensagem(nome_mensagem)
    with open(PASTA_MENSAGENS / nome_arquivo, 'rb') as f:
        mensagens = pickle.load(f)
    return mensagens[key]


def listar_conversas() -> list:
    """
    Lista todas as conversas salvas, ordenadas pela √∫ltima modifica√ß√£o.

    Retorno:
    \n\t`list`: Lista dos nomes das conversas armazenadas, ordenadas da mais recente para a mais antiga.

    Exemplo:
    >>> listar_conversas()
    ['conversa1', 'conversa2']
    """
    conversas = list(PASTA_MENSAGENS.glob('*'))
    conversas = sorted(
        conversas, key=lambda item: item.stat().st_mtime_ns, reverse=True)
    return [c.stem for c in conversas]


# SALVAMENTO E LEITURA DA APIKEY ========================

def salva_chave(chave: str) -> None:
    """
    Salva a chave da API da OpenAI em um arquivo utilizando serializa√ß√£o com `pickle`.

    Par√¢metros:
    \n\t`chave (str)`: Chave da API a ser salva.

    Exemplo:
    >>> salva_chave("sk-12345ABCDE67890FGHIJ")
    """
    with open(PASTA_CONFIGERACOES / 'chave', 'wb') as f:
        pickle.dump(chave, f)


def le_chave() -> str:
    """
    L√™ a chave da API salva em um arquivo ou do arquivo .env.

    Retorno:
    \n\t`str`: Chave lida do arquivo ou do ambiente. Retorna uma string vazia se n√£o for encontrada.

    Exemplo:
    >>> le_chave()
    'sk-12345ABCDE67890FGHIJ'
    """
    if (PASTA_CONFIGERACOES / 'chave').exists():
        with open(PASTA_CONFIGERACOES / 'chave', 'rb') as f:
            return pickle.load(f)
    else:
        # Obt√©m a chave da API do arquivo .env
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            return api_key
        else:
            return ''


# RAG com LANGCHAIN ========================

def importacao_documentos() -> list:
    """
    Carrega documentos PDF da pasta de arquivos e os transforma em uma lista de documentos process√°veis.

    Retorno:
    \n\t`list`: Lista de documentos carregados a partir dos arquivos PDF dispon√≠veis.

    Exemplo:
    >>> documentos = importacao_documentos()
    >>> print(len(documentos))
    5
    """
    documentos = []
    for arquivo in PASTA_ARQUIVOS.glob('*.pdf'):
        loader = PyPDFLoader(str(arquivo))
        documentos_arquivo = loader.load()
        documentos.extend(documentos_arquivo)
    return documentos


def split_de_documentos(documentos: list) -> list:
    """
    Divide documentos longos em trechos menores para facilitar a recupera√ß√£o de informa√ß√µes.

    Par√¢metros:
    \n\t`documentos (list)`: Lista de documentos a serem fragmentados.

    Retorno:
    \n\t`list`: Lista de documentos segmentados, prontos para processamento.

    Exemplo:
    >>> documentos = split_de_documentos(importacao_documentos())
    >>> print(len(documentos))
    20
    """
    recur_splitter = RecursiveCharacterTextSplitter(
        chunk_size=2500,
        chunk_overlap=250,
        separators=["/n\n", "\n", ".", " ", ""]
    )
    documentos = recur_splitter.split_documents(documentos)

    for i, doc in enumerate(documentos):
        doc.metadata['source'] = doc.metadata['source'].split('/')[-1]
        doc.metadata['doc_id'] = i
    return documentos


def cria_vector_store(documentos: list):
    """
    Cria um armazenamento vetorial utilizando FAISS a partir de uma lista de documentos segmentados.

    Par√¢metros:
    \n\t`documentos (list)`: Lista de documentos processados e divididos em trechos menores.

    Retorno:
    \n\t`FAISS`: Um √≠ndice FAISS contendo os embeddings dos documentos para recupera√ß√£o eficiente de informa√ß√µes.

    Exemplo:
    >>> documentos = split_de_documentos(importacao_documentos())
    >>> vector_store = cria_vector_store(documentos)
    >>> print(vector_store)
    <langchain_community.vectorstores.faiss.FAISS object at 0x...>
    """
    try:
        embedding_model = OpenAIEmbeddings()
        print("Embedding model initialized successfully.")
        vector_store = FAISS.from_documents(
            documents=documentos,
            embedding=embedding_model
        )
        print("DEBUG: Tipo de vector_store:", type(vector_store))
        print("DEBUG: Conte√∫do de vector_store:", vector_store)

        return vector_store
    except Exception as e:
        print("Failed to initialize embedding model:", e)


def cria_chain_conversa():
    """
    Cria a cadeia de conversa√ß√£o utilizando LangChain para recupera√ß√£o de informa√ß√µes baseada em conversas anteriores e documentos fornecidos.

    Retorno:
    \n\t`None`: A fun√ß√£o n√£o retorna nada explicitamente, mas armazena a cadeia no estado da sess√£o do Streamlit.

    Exemplo:
    >>> cria_chain_conversa()
    >>> print(st.session_state['chain'])
    <langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain object at 0x...>
    """

    documentos = importacao_documentos()
    documentos = split_de_documentos(documentos)
    vector_store = cria_vector_store(documentos)

    chat = ChatOpenAI(model=get_config('modelo'))
    memory = ConversationBufferMemory(
        return_messages=True,
        memory_key='chat_history',
        output_key='answer'
    )
    retriever = vector_store.as_retriever(
        search_type=get_config('retrieval_search_type'),
        search_kwargs=get_config('retrieval_kwargs')
    )
    prompt = PromptTemplate.from_template(get_config('prompt'))
    chat_chain = ConversationalRetrievalChain.from_llm(
        llm=chat,
        memory=memory,
        retriever=retriever,
        return_source_documents=True,
        verbose=True,
        combine_docs_chain_kwargs={'prompt': prompt}
    )

    st.session_state['chain'] = chat_chain


# FUN√á√ïES ==================================================


def seleciona_conversa(nome_arquivo: str) -> None:
    """
    Seleciona uma conversa existente ou cria uma nova sess√£o de conversa.

    Par√¢metros:
    \n\t`nome_arquivo (str)`: Nome do arquivo da conversa a ser carregada. Se for uma string vazia, inicia uma nova conversa.

    Retorno:
    \n\t`None`: Atualiza o estado da sess√£o do Streamlit com a conversa selecionada.

    Exemplo:
    >>> seleciona_conversa('conversa1')
    >>> print(st.session_state['conversa_atual'])
    'conversa1'
    """
    if nome_arquivo == '':
        st.session_state['mensagens'] = []
    else:
        mensagem = ler_mensagem_por_nome_arquivo(nome_arquivo)
        st.session_state['mensagens'] = mensagem
    st.session_state['conversa_atual'] = nome_arquivo


def mascarar_chave(chave: str) -> str:
    """
    Mascarar uma chave API para exibi√ß√£o segura, ocultando parte dos caracteres.

    Par√¢metros:
    \n\t`chave (str)`: A chave API a ser mascarada.

    Retorno:
    \n\t`str`: Chave mascarada com os primeiros 5 e os √∫ltimos 5 caracteres vis√≠veis.

    Exemplo:
    >>> mascarar_chave("sk-12345ABCDE67890FGHIJ")
    'sk-12345***FGHIJ'
    """
    if len(chave) > 10:
        return chave[:5] + '***' + chave[-5:]
    else:
        return chave


def nova_mensagem(prompt: str, mensagens: list, flag: bool = False, placeholder=None) -> None:
    """
    Adiciona uma nova mensagem ao hist√≥rico de conversas e exibe a intera√ß√£o com o chatbot.

    Par√¢metros:
    \n\t`prompt (str)`: Texto da mensagem enviada pelo usu√°rio.
    \n\t`mensagens (list)`: Lista contendo o hist√≥rico das mensagens da conversa.
    \n\t`flag (bool)`: Se `True`, exibe a mensagem visualmente no chat.
    \n\t`placeholder`: Elemento do Streamlit utilizado para atualizar mensagens em tempo real.

    Retorno:
    \n\t`None`: Atualiza o estado da sess√£o do Streamlit e exibe a intera√ß√£o.

    Exemplo:
    >>> mensagens = []
    >>> nova_mensagem("Ol√°!", mensagens, True)
    """
    st.session_state['show_modal'] = False

    """
    Processa a mensagem do usu√°rio e obt√©m a resposta do assistente via streaming,
    usando a fun√ß√£o retorna_resposta_modelo().

    - Adiciona a mensagem do usu√°rio ao hist√≥rico.
    - Faz a chamada √† API em modo streaming.
    - Para cada chunk recebido, o token √© acumulado e yieldado.
    - Ao final, adiciona a resposta completa (do assistente) ao hist√≥rico,
      salva e atualiza o st.session_state.

    Retorna (via yield) os peda√ßos de resposta do assistente.
    """

    """
    Recebe o prompt do usu√°rio, chama retorna_resposta_modelo() em modo streaming,
    yieldando peda√ßos de texto do assistente.
    N√£o exibe nada no Streamlit. A exibi√ß√£o fica no pg_conversas().
    """
    # Adiciona mensagem do usu√°rio ao hist√≥rico
    nova_msg_usuario = {"role": "user", "content": prompt}
    mensagens.append(nova_msg_usuario)

    resposta_completa = ""
    try:
        # Chamamos retorna_resposta_modelo com stream=True
        for line in retorna_resposta_modelo(
            mensagens,
            st.session_state['api_key'],
            modelo=st.session_state['modelo'],
            stream=True
        ):
            if not line.startswith("data: "):
                continue
            if line.strip() == "data: [DONE]":
                break

            conteudo_json = line[len("data: "):]
            try:
                pedaco = json.loads(conteudo_json)
            except json.JSONDecodeError:
                continue

            delta = pedaco.get("choices", [{}])[0].get("delta", {})
            content = delta.get("content", "")
            resposta_completa += content
            yield content

    except Exception as e:
        yield f"[ERRO]: {e}"

    # Ao final, adiciona a resposta ao hist√≥rico
    nova_msg_assistente = {"role": "assistant", "content": resposta_completa}
    mensagens.append(nova_msg_assistente)
    st.session_state['mensagens'] = mensagens
    salvar_mensagens(mensagens)

    # ---

    # # Adiciona a mensagem do usu√°rio ao hist√≥rico
    # nova_msg_usuario = {"role": "user", "content": prompt}
    # mensagens.append(nova_msg_usuario)

    # resposta_completa = ""
    # try:
    #     for line in retorna_resposta_modelo(
    #         mensagens,
    #         st.session_state['api_key'],
    #         modelo=st.session_state['modelo'],
    #         temperatura=0,
    #         stream=True
    #     ):
    #         # Filtra linhas √∫teis
    #         if not line.startswith("data: "):
    #             continue
    #         if line.strip() == "data: [DONE]":
    #             break

    #         conteudo_json = line[len("data: "):]
    #         try:
    #             pedaco = json.loads(conteudo_json)
    #         except json.JSONDecodeError:
    #             continue

    #         delta = pedaco.get("choices", [{}])[0].get("delta", {})
    #         content = delta.get("content", "")
    #         resposta_completa += content
    #         yield content  # Yield do chunk para o streaming

    # except Exception as e:
    #     yield f"[ERRO]: {e}"

    # # Ao final, adiciona a resposta completa ao hist√≥rico
    # nova_msg_assistente = {"role": "assistant", "content": resposta_completa}
    # mensagens.append(nova_msg_assistente)
    # salvar_mensagens(mensagens)
    # st.session_state['mensagens'] = mensagens

    # ---

    # nova_mensagem = {'role': 'user', 'content': prompt}

    # mensagens.append(nova_mensagem)

    # if flag:
    #     chat = st.chat_message(nova_mensagem['role'])
    #     chat.markdown(
    #         f'<div class="user-message">{nova_mensagem["content"]}</div>', unsafe_allow_html=True)

    #     chat = st.chat_message('assistant')

    #     placeholder = chat.empty()

    #     placeholder.markdown(
    #         "<div class='assistant-message'>‚ñå </div>", unsafe_allow_html=True)

    # # resposta_completa = ''
    # resposta_completa = ""

    # try:
    #     respostas = retorna_resposta_modelo(
    #         mensagens,
    #         st.session_state['api_key'],
    #         modelo=st.session_state['modelo'],
    #         stream=True,
    #     )

    #     for linha in respostas:
    #         # Se a linha n√£o come√ßar com 'data: ', pule.
    #         if not linha.startswith("data: "):
    #             continue

    #         # Se for a linha de encerramento [DONE], saia do loop.
    #         if linha.strip() == "data: [DONE]":
    #             break

    #         # Remova 'data: ' do in√≠cio para tentar fazer JSON parse
    #         conteudo_json = linha[len("data: "):]

    #         try:
    #             pedaco = json.loads(conteudo_json)
    #         except json.JSONDecodeError:
    #             # Simplesmente ignore se n√£o for JSON v√°lido
    #             continue

    #         delta = pedaco.get("choices", [{}])[0].get("delta", {})
    #         content = delta.get("content", "")

    #         # Concatena apenas o texto novo
    #         resposta_completa += content

    #         # Se estiver exibindo no chat, atualize o placeholder
    #         if flag:
    #             placeholder.markdown(
    #                 f"<div class='assistant-message'>{resposta_completa}‚ñå</div>",
    #                 unsafe_allow_html=True
    #             )

    #     # Ao final, se quiser remover o cursor ‚ñå, pode atualizar o placeholder de novo:
    #     if flag:
    #         placeholder.markdown(
    #             f"<div class='assistant-message'>{resposta_completa}</div>",
    #             unsafe_allow_html=True
    #         )

    #     nova_mensagem = {'role': 'assistant',
    #                      'content': resposta_completa}

    #     st.session_state['mensagens'] = mensagens

    #     mensagens.append(nova_mensagem)

    #     print(f"\n[Requisi√ß√£o do Usu√°rio]:\n \033[35m{prompt}\033[0m \n")
    #     print(
    #         f"[Resposta do Chat de Conversa]:\n \033[31m{resposta_completa}\033[0m \n\n")

    #     salvar_mensagens(mensagens)

    #     placeholder = None

    #     if placeholder is None:
    #         st.rerun()

    # except requests.exceptions.HTTPError as e:
    #     st.error(
    #         'üò£ Desculpe, mas o ChatGPT est√° indispon√≠vel no momento.')
    #     print(f"Erro HTTP: {e}")

    # except Exception as e:
    #     st.error(
    #         'üò´ Ocorreu um erro inesperado. Por favor, tente novamente mais tarde.')
    #     print(f"Erro inesperado: {e}")


def transcreve_audio(caminho_audio: str, prompt: str, headers: dict, _return: bool = True):
    """
    Transcreve um arquivo de √°udio utilizando a API da OpenAI (Whisper-1).

    Par√¢metros:
    \n\t`caminho_audio (str)`: Caminho do arquivo de √°udio que ser√° transcrito.
    \n\t`prompt (str)`: Sugest√£o opcional para orientar a transcri√ß√£o.
    \n\t`headers (dict)`: Cabe√ßalhos HTTP contendo a chave da API e outras configura√ß√µes.
    \n\t`_return (bool)`: Se `True`, exibe a transcri√ß√£o no Streamlit; se `False`, apenas armazena no estado da sess√£o.

    Retorno:
    \n\t`str | None`: Retorna a transcri√ß√£o do √°udio se `_return` for `True`, ou `None` caso contr√°rio.

    Exemplo:
    >>> headers = {"Authorization": "Bearer minha_api_key"}
    >>> transcricao = transcreve_audio("audio.mp3", "Transcreva este √°udio.", headers)
    >>> print(transcricao)
    "Este √© o conte√∫do do √°udio transcrito."
    """

    with open(caminho_audio, 'rb') as arquivo_audio:
        audio_bytes = arquivo_audio.read()
        # Preparar o MultipartEncoder (alternativo)
        # m = MultipartEncoder(
        #     fields={
        #         'file': ('audio.mp3', BytesIO(audio_bytes), 'audio/mpeg'),
        #         'prompt': prompt_input,
        #         'model': 'whisper-1',
        #         'language': 'pt',
        #         'response_format': 'text'
        #     }
        # )
        # headers['Content-Type'] = m.content_type
        files = {
            'file': ('audio.mp3', BytesIO(audio_bytes), 'audio/mpeg'),
            'model': (None, 'whisper-1'),
            'language': (None, 'pt'),
            'response_format': (None, 'text'),
            'prompt': (None, prompt)
        }

        response = requests.post(
            # "https://api.openai.com/v1/audio/transcriptions", headers=headers, data=m)
            "https://api.openai.com/v1/audio/transcriptions", headers=headers, files=files)

        try:
            if response.status_code == 200:
                transcricao = response.text
                st.session_state['transcricao'] = transcricao
                if _return:
                    return st.markdown(f'<div class="st-key-transcricao">{transcricao}</div><br/>', unsafe_allow_html=True)
                else:
                    return None

            else:
                print(f"Erro: {response.status_code}")
                print("Erro ao decodificar a resposta da API. Resposta:")
                print(response.text)
                return st.error(f"Erro: {response.status_code} ao decodificar a resposta da API. Veja os detalhes no terminal.")

        except ValueError:
            print(f"Erro: {response.status_code}")
            print("Erro ao decodificar a resposta da API. Resposta:")
            print(response.text)
            return st.error("Erro ao decodificar a resposta da API. Veja os detalhes no terminal.")


def adiciona_chunck_de_audio(frames_de_audio: list, chunck_audio) -> object:
    """
    Adiciona um conjunto de frames de √°udio a um segmento de √°udio existente.

    Par√¢metros:
    \n\t`frames_de_audio (list)`: Lista de frames de √°udio que ser√£o adicionados ao segmento de √°udio.
    \n\t`chunck_audio (pydub.AudioSegment)`: Segmento de √°udio onde os frames ser√£o concatenados.

    Retorno:
    \n\t`pydub.AudioSegment`: O segmento de √°udio atualizado com os frames adicionados.

    Exemplo:
    >>> from pydub import AudioSegment
    >>> chunck_audio = AudioSegment.silent(duration=1000)  # √Åudio de 1 segundo de sil√™ncio
    >>> frames = [AudioSegment.silent(duration=500), AudioSegment.silent(duration=500)]
    >>> novo_audio = adiciona_chunck_de_audio(frames, chunck_audio)
    >>> print(len(novo_audio))
    2000  # O √°udio agora tem 2 segundos de dura√ß√£o
    """
    for frame in frames_de_audio:
        sound = pydub.AudioSegment(
            data=frame.to_ndarray().tobytes(),
            sample_width=frame.format.bytes,
            frame_rate=frame.sample_rate,
            channels=len(frame.layout.channels)
        )
        chunck_audio += sound
    return chunck_audio


# TRANSCREVE VIDEO =====================================

def _salva_audio_do_video(video_bytes: BytesIO) -> str:
    """
    Extrai e salva o √°udio de um arquivo de v√≠deo.

    Par√¢metros:
    \n\t`video_bytes (BytesIO)`: Objeto contendo os bytes do v√≠deo a ser processado.

    Retorno:
    \n\t`str`: Retorna a string "Continue" ap√≥s a extra√ß√£o do √°udio ser conclu√≠da com sucesso.

    Exemplo:
    >>> with open("video.mp4", "rb") as f:
    >>>     video_bytes = BytesIO(f.read())
    >>> _salva_audio_do_video(video_bytes)
    "Continue"
    """
    with open(ARQUIVO_VIDEO_TEMP, mode='wb') as video_f:
        video_f.write(video_bytes.read())
    moviepy_video = VideoFileClip(str(ARQUIVO_VIDEO_TEMP))
    moviepy_video.audio.write_audiofile(str(ARQUIVO_AUDIO_TEMP))
    return "Continue"


@st.dialog("Enviar √°udio por v√≠deo mp4")
def transcreve_video_recebido():
    """
    Transcreve o √°udio de um v√≠deo enviado pelo usu√°rio.

    Opera√ß√µes:
    \n\t- Exibe um campo para entrada de um prompt opcional.
    \n\t- Permite o upload de um arquivo de v√≠deo no formato `.mp4`.
    \n\t- Salva o √°udio extra√≠do do v√≠deo temporariamente.
    \n\t- Envia o √°udio para transcri√ß√£o utilizando a API da OpenAI (Whisper-1).
    \n\t- Exibe a transcri√ß√£o resultante.

    Retorno:
    \n\t`None`: Apenas exibe a transcri√ß√£o do √°udio no Streamlit.

    Exemplo:
    >>> transcreve_video_recebido()
    """

    if st.session_state['api_key'] == '':
        st.error('Adicone uma chave de api na aba de configura√ß√µes')
    else:
        headers = {
            "Authorization": f"Bearer {st.session_state['api_key']}"
        }
        prompt_video = st.text_input(
            '(opcional) Sugest√£o para orientar a transcri√ß√£o.',
            key='input_video')
        st.info(
            "**Arraste e solte o arquivo no campo abaixo ou clique em 'Browse Files' para selecionar um arquivo.**")
        arquivo_video = st.file_uploader('Adicione um arquivo de v√≠deo .mp4', type=[
                                         'mp4'], label_visibility='collapsed')

        if arquivo_video is not None and st.session_state['transcricao'] == '':
            with st.spinner('Convertendo o v√≠deo para √°udio...'):
                flag_continue = _salva_audio_do_video(arquivo_video)

            if not flag_continue is None and st.session_state['transcricao'] == '':
                with st.spinner('Processando o √°udio...'):
                    st.info(
                        "Sua transcri√ß√£o est√° sendo preparada para ser enviada!")
                    transcreve_audio(ARQUIVO_AUDIO_TEMP,
                                     prompt_video, headers, False)
                    flag_continue = None
                    arquivo_video = None

                    print(st.session_state['transcricao'])

                    # with st.spinner('Processando a resposta...'):
                    #     nova_mensagem_wrapper(st.session_state['transcricao'],
                    #                           st.session_state['mensagens'],
                    #                           False,
                    #                           None)
                    #     st.rerun()

                    with st.spinner('Processando a resposta...'):
                        # resposta_acumulada = ""
                        # for chunk in nova_mensagem_wrapper(st.session_state['transcricao'],
                        #                                    st.session_state['mensagens'],
                        #                                    False,
                        #                                    None):
                        #     resposta_acumulada += chunk
                        #     # ou atualize um placeholder se preferir
                        #     st.write(resposta_acumulada)
                        with st.spinner('Processando a resposta...'):
                            resposta_completa = nova_mensagem_wrapper(
                                st.session_state['transcricao'], st.session_state['mensagens'])
                            # Se quiser fazer algo adicional com o texto final:
                            st.write("Debug - Resposta final:",
                                     resposta_completa)

                        st.rerun()

    if st.button("Fechar", key="Fechar"):
        js_debug("Bot√£o Fechar")
        js_debug(st.session_state['transcricao'])
        arquivo_video = None
        st.session_state['transcricao'] = ''
        st.session_state['show_modal'] = False
        st.rerun()


# TRANSCREVE AUDIO =====================================

@st.dialog("Enviar √°udio por arquivo mp3")
def transcreve_audio_recebido():
    """
    Transcreve um arquivo de √°udio enviado pelo usu√°rio.

    Opera√ß√µes:
    \n\t- Exibe um campo para entrada de um prompt opcional.
    \n\t- Permite o upload de um arquivo de √°udio no formato `.mp3`.
    \n\t- Envia o √°udio para transcri√ß√£o utilizando a API da OpenAI (Whisper-1).
    \n\t- Exibe a transcri√ß√£o resultante ou uma mensagem de erro, se necess√°rio.

    Retorno:
    \n\t`None`: Apenas exibe a transcri√ß√£o do √°udio no Streamlit.

    Exemplo:
    >>> transcreve_audio_recebido()
    """
    if st.session_state['api_key'] == '':
        st.error('Adicone uma chave de api na aba de configura√ß√µes')
    else:
        headers = {
            "Authorization": f"Bearer {st.session_state['api_key']}"
        }
        prompt_input = st.text_input(
            '(opcional) Sugest√£o para orientar a transcri√ß√£o.',
            key='input_audio')
        st.info(
            "**Arraste e solte o arquivo no campo abaixo ou clique em 'Browse Files' para selecionar um arquivo.**")
        arquivo_audio = st.file_uploader('Adicione um arquivo de √°udio .mp3', type=[
            'mp3'], label_visibility='collapsed')

        if arquivo_audio is not None and st.session_state['transcricao'] == '':
            audio_bytes = arquivo_audio.read()

            files = {
                'file': ('audio.mp3', BytesIO(audio_bytes), 'audio/mpeg'),
                'model': (None, 'whisper-1'),
                'language': (None, 'pt'),
                'response_format': (None, 'text'),
                'prompt': (None, prompt_input)
            }
            with st.spinner('Processando o √°udio...'):
                response = requests.post(
                    "https://api.openai.com/v1/audio/transcriptions", headers=headers, files=files)

                try:
                    if response.status_code == 200:
                        st.info(
                            "Sua transcri√ß√£o est√° sendo preparada para ser enviada!")
                        transcricao = response.text
                        st.session_state['transcricao'] = transcricao
                        arquivo_audio = None

                        print(st.session_state['transcricao'])

                        with st.spinner('Processando a resposta...'):
                            resposta_completa = nova_mensagem_wrapper(
                                transcricao, st.session_state['mensagens'])
                            st.rerun()

                    else:
                        st.error(
                            f"Erro: {response.status_code} ao decodificar a resposta da API. Veja os detalhes no terminal.")
                        print(f"Erro: {response.status_code}")
                        print("Erro ao decodificar a resposta da API. Resposta:")
                        print(response.text)

                except ValueError:
                    st.error(
                        "Erro ao decodificar a resposta da API. Veja os detalhes no terminal.")
                    print(f"Erro: {response.status_code}")
                    print("Erro ao decodificar a resposta da API. Resposta:")
                    print(response.text)
                    st.write(response.status_code)

        if st.button("Fechar", key="Fechar"):
            js_debug("Bot√£o Fechar")
            js_debug(st.session_state['transcricao'])
            arquivo_audio = None
            st.session_state['transcricao'] = ''
            st.session_state['show_modal'] = False
            st.rerun()


def nova_mensagem_wrapper(prompt: str, mensagens: list):
    """
    Fun√ß√£o wrapper que:
      - Concatena a transcri√ß√£o ao prompt (se houver),
      - Chama nova_mensagem() em modo streaming,
      - Faz a itera√ß√£o dos chunks internamente
      - Exibe e/ou retorna a resposta completa.
    """

    # 1) Concatena a transcri√ß√£o, se existir
    transcricao = st.session_state.get('transcricao', '').strip()
    if transcricao:
        prompt = f"Transcri√ß√£o do √°udio:\n{transcricao}\n\nPergunta do usu√°rio:\n{prompt}"
        # Limpa a transcri√ß√£o para n√£o reutilizar em chamadas futuras
        st.session_state['transcricao'] = ''

    # 2) Cria um placeholder para exibirmos (opcional, se quiser streaming visual)
    placeholder_assistant = st.chat_message('assistant').empty()

    # 3) Faz a itera√ß√£o sobre nova_mensagem e exibe peda√ßos de resposta
    resposta_acumulada = ""
    for chunk in nova_mensagem(prompt, mensagens):
        resposta_acumulada += chunk
        # Exemplo: atualizar o placeholder em tempo real (streaming)
        placeholder_assistant.markdown(
            f"<div class='assistant-message'>{resposta_acumulada}<span></span></div>",
            unsafe_allow_html=True
        )

    # 4) Ao final, retorna (ou exibe) a resposta completa
    return resposta_acumulada


def renderizar_mensagens(mensagens: list, placeholder=None) -> None:
    """
    Renderiza as mensagens da conversa na interface do Streamlit.

    Par√¢metros:
    \n\t`mensagens (list)`: Lista contendo as mensagens a serem exibidas.
    \n\t`placeholder`: Elemento opcional do Streamlit para atualiza√ß√£o din√¢mica.

    Retorno:
    \n\t`None`: Apenas exibe as mensagens na interface.

    Exemplo:
    >>> mensagens = [
    >>>     {"role": "user", "content": "Ol√°!"},
    >>>     {"role": "assistant", "content": "Oi! Como posso te ajudar?"}
    >>> ]
    >>> renderizar_mensagens(mensagens)
    """
    for mensagem in mensagens:
        if mensagem['role'] == 'user':
            chat = st.chat_message(mensagem['role'])
            chat.markdown(
                f'<div class="user-message">{mensagem["content"]}</div>', unsafe_allow_html=True)
        elif mensagem['role'] == 'assistant' and placeholder is None:
            chat = st.chat_message(mensagens['role'])
            chat.markdown(
                f'<div class="assistant-message">{mensagens["content"]}</div>', unsafe_allow_html=True)
        if placeholder is not None:
            placeholder.markdown(
                "<div class='assistant-message'><span>‚ñå</span></div>", unsafe_allow_html=True)


# P√ÅGINA PRINCIPAL ==================================================

# P√ÅGINA de Converas =========================

def pg_conversas() -> None:
    """
    Exibe a interface principal do chat baseado em LLM (Large Language Model).

    Opera√ß√µes:
    \n\t- Exibe o cabe√ßalho do chat.
    \n\t- Carrega e renderiza as mensagens da conversa.
    \n\t- Exibe um campo de entrada de mensagens para intera√ß√£o do usu√°rio.
    \n\t- Permite a sele√ß√£o de diferentes formatos de entrada (texto, √°udio, v√≠deo).
    \n\t- Gerencia a l√≥gica de envio da mensagem e processamento da resposta.

    Retorno:
    \n\t`None`: Apenas exibe a interface e gerencia as intera√ß√µes no Streamlit.

    Exemplo:
    >>> pg_conversas()
    """

    """
    Exibe o hist√≥rico completo do chat e gerencia a intera√ß√£o com o usu√°rio.
    Toda a renderiza√ß√£o √© feita aqui:
      - Exibe mensagens anteriores (usu√°rio e assistente).
      - Captura o prompt via st.chat_input().
      - Exibe imediatamente a mensagem do usu√°rio.
      - Cria um placeholder para o assistente e atualiza-o em streaming,
        consumindo os chunks yieldados por nova_mensagem().
    """

    """
    Exibe todo o hist√≥rico e gerencia a conversa.
    O 'st.chat_input()' fica sempre no rodap√©,
    mas tudo que for exibido (mensagens antigas, mensagem nova do usu√°rio e do assistente)
    acontece ANTES do chat_input no c√≥digo.
    """

    """
    Exibe todo o hist√≥rico e gerencia a conversa.
    O 'st.chat_input()' fica sempre no rodap√©,
    mas agora est√° envolvido em um container 'footer' para melhor organiza√ß√£o.
    """

    st.header('üó®Ô∏è Chat de Conversas - LLM', divider=True)

    # Carrega hist√≥rico
    if 'mensagens' not in st.session_state:
        st.session_state['mensagens'] = []
    mensagens = ler_mensagens(st.session_state['mensagens'])

    # 1) Exibe o hist√≥rico anterior (usu√°rio e assistente)
    for msg in mensagens:
        if msg['role'] == 'user':
            st.chat_message('user').markdown(
                f"<div class='user-message'>{msg['content']}</div>",
                unsafe_allow_html=True
            )
        else:
            st.chat_message('assistant').markdown(
                f"<div class='assistant-message'>{msg['content']}</div>",
                unsafe_allow_html=True
            )

    # 2) Agora criamos um container 'footer' para o campo de entrada e outros elementos
    with st.container(key='footer'):
        # Campo de entrada do chat (fixado ao rodap√© por padr√£o do Streamlit)
        prompt = st.chat_input('Fale com o tutor')

        col1, col2 = st.columns([1, 3])  # Ajuste as larguras como quiser

        with col1:
            options_pills = ["‚å®Ô∏è", "üé§", "üìΩÔ∏è"]
            seleciona_midia = st.pills(
                "Selecione a M√≠dia",
                options_pills,
                selection_mode="single",
                key='input-select',
                label_visibility="hidden"
            )
            st.session_state['input'] = seleciona_midia
            js_debug(st.session_state['input'])

            if st.session_state['input'] == "‚å®Ô∏è":
                js_debug("reinicia o modal")
                st.session_state['show_modal'] = True
                st.session_state['transcricao'] = ''
            elif st.session_state['input'] == "üé§" and st.session_state['show_modal']:
                js_debug("transcreve_audio_recebido()")
                st.session_state['input'] = "‚å®Ô∏è"
                transcreve_audio_recebido()
            elif st.session_state['input'] == "üìΩÔ∏è" and st.session_state['show_modal']:
                js_debug("transcreve_video_recebido()")
                st.session_state['input'] = "‚å®Ô∏è"
                transcreve_video_recebido()

        with col2:
            st.markdown(
                "<small>O Chat de Conversas pode cometer erros. Considere verificar informa√ß√µes importantes.</small>", unsafe_allow_html=True)

    # 3) Se o usu√°rio digitou algo
    if prompt:
        if st.session_state['api_key'] == '':
            st.error('Adicione uma chave de API na aba de configura√ß√µes')
        else:
            # a) Exibe imediatamente a mensagem do usu√°rio
            st.chat_message('user').markdown(
                f"<div class='user-message'>{prompt}</div>",
                unsafe_allow_html=True
            )

            # b) Cria um placeholder para o assistente
            placeholder_assistant = st.chat_message('assistant').empty()

            # c) Faz o streaming (chama nova_mensagem)
            resposta_acumulada = ""
            for chunk in nova_mensagem(prompt, mensagens):
                resposta_acumulada += chunk
                placeholder_assistant.markdown(
                    f"<div class='assistant-message'>{resposta_acumulada}<span></span></div>", unsafe_allow_html=True)

            # d) Ao final, exibe a resposta sem o cursor
            placeholder_assistant.markdown(
                f"<div class='assistant-message'>{resposta_acumulada}</div>",
                unsafe_allow_html=True
            )

    # ---

    # st.header('üó®Ô∏è Chat de Conversas - LLM', divider=True)

    # # Carrega hist√≥rico
    # if 'mensagens' not in st.session_state:
    #     st.session_state['mensagens'] = []
    # mensagens = ler_mensagens(st.session_state['mensagens'])

    # # 1) Exibe o hist√≥rico anterior
    # for msg in mensagens:
    #     if msg['role'] == 'user':
    #         st.chat_message('user').markdown(
    #             f"<div class='user-message'>{msg['content']}</div>",
    #             unsafe_allow_html=True
    #         )
    #     else:
    #         st.chat_message('assistant').markdown(
    #             f"<div class='assistant-message'>{msg['content']}</div>",
    #             unsafe_allow_html=True
    #         )

    # # 2) Se houver alguma mensagem rec√©m-enviada (guardada em st.session_state),
    # #    mas ainda n√£o exibida, voc√™ poderia exibir aqui antes do input.
    # #    (Geralmente n√£o precisa, pois j√° est√° no hist√≥rico.)

    # # 3) Verifica se existe alguma mensagem pendente de streaming
    # #    (Cen√°rio: se voc√™ n√£o finalizou o streaming na mesma execu√ß√£o)
    # #    Normalmente, no Streamlit, o streaming ocorre na mesma reexecu√ß√£o do prompt,
    # #    ent√£o n√£o √© preciso algo adicional aqui.

    # # 4) Agora exibimos o campo de entrada (chat_input) - ele fica fixado no rodap√©
    # prompt = st.chat_input('Fale com o tutor')

    # # Exemplo: pills de m√≠dia
    # options_pills = ["‚å®Ô∏è", "üé§", "üìΩÔ∏è"]
    # seleciona_midia = st.pills(
    #     "Selecione a M√≠dia",
    #     options_pills,
    #     selection_mode="single",
    #     key='input-select',
    #     label_visibility="hidden"
    # )
    # st.session_state['input'] = seleciona_midia
    # js_debug(st.session_state['input'])

    # if st.session_state['input'] == "‚å®Ô∏è":
    #     js_debug("reinicia o modal")
    #     st.session_state['show_modal'] = True
    #     st.session_state['transcricao'] = ''
    # elif st.session_state['input'] == "üé§" and st.session_state['show_modal']:
    #     js_debug("transcreve_audio_recebido()")
    #     st.session_state['input'] = "‚å®Ô∏è"
    #     transcreve_audio_recebido()
    # elif st.session_state['input'] == "üìΩÔ∏è" and st.session_state['show_modal']:
    #     js_debug("transcreve_video_recebido()")
    #     st.session_state['input'] = "‚å®Ô∏è"
    #     transcreve_video_recebido()

    # st.markdown(
    #     '_O Chat de Conversas pode cometer erros. Considere verificar informa√ß√µes importantes._')

    # # 5) Se o usu√°rio digitou algo no chat_input
    # if prompt:
    #     if st.session_state['api_key'] == '':
    #         st.error('Adicione uma chave de API na aba de configura√ß√µes')
    #     else:
    #         # a) Exibe imediatamente a mensagem do usu√°rio
    #         st.chat_message('user').markdown(
    #             f"<div class='user-message'>{prompt}</div>",
    #             unsafe_allow_html=True
    #         )

    #         # b) Cria um placeholder para o assistente
    #         placeholder_assistant = st.chat_message('assistant').empty()

    #         # c) Faz o streaming (chama nova_mensagem)
    #         resposta_acumulada = ""
    #         for chunk in nova_mensagem(prompt, mensagens):
    #             resposta_acumulada += chunk
    #             placeholder_assistant.markdown(
    #                 f"<div class='assistant-message'>{resposta_acumulada}</div>",
    #                 unsafe_allow_html=True
    #             )

    #         # d) Ao final, exibe a resposta sem o cursor
    #         placeholder_assistant.markdown(
    #             f"<div class='assistant-message'>{resposta_acumulada}</div>",
    #             unsafe_allow_html=True
    #         )

    #         # e) Fim. A pr√≥xima reexecu√ß√£o do script vai redesenhar tudo acima do chat_input.

    # ---

    # st.header('üó®Ô∏è Chat de Conversas - LLM', divider=True)

    # # Carrega o hist√≥rico de mensagens do session_state
    # if 'mensagens' not in st.session_state:
    #     st.session_state['mensagens'] = []
    # mensagens = ler_mensagens(st.session_state['mensagens'])

    # # Exibe o hist√≥rico anterior
    # for msg in mensagens:
    #     if msg['role'] == 'user':
    #         st.chat_message('user').markdown(
    #             f"<div class='user-message'>{msg['content']}</div>",
    #             unsafe_allow_html=True
    #         )
    #     else:
    #         st.chat_message('assistant').markdown(
    #             f"<div class='assistant-message'>{msg['content']}</div>",
    #             unsafe_allow_html=True
    #         )

    # # √Årea de entrada do chat (fixada no rodap√©)
    # with st.container(key='footer'):
    #     prompt = st.chat_input('Fale com o tutor')

    #     options_pills = ["‚å®Ô∏è", "üé§", "üìΩÔ∏è"]
    #     seleciona_midia = st.pills(
    #         "Selecione a M√≠dia",
    #         options_pills,
    #         selection_mode="single",
    #         key='input-select',
    #         label_visibility="hidden"
    #     )
    #     st.session_state['input'] = seleciona_midia
    #     js_debug(st.session_state['input'])

    #     if st.session_state['input'] == "‚å®Ô∏è":
    #         js_debug("reinicia o modal")
    #         st.session_state['show_modal'] = True
    #         st.session_state['transcricao'] = ''
    #     elif st.session_state['input'] == "üé§" and st.session_state['show_modal']:
    #         js_debug("transcreve_audio_recebido()")
    #         st.session_state['input'] = "‚å®Ô∏è"
    #         transcreve_audio_recebido()
    #     elif st.session_state['input'] == "üìΩÔ∏è" and st.session_state['show_modal']:
    #         js_debug("transcreve_video_recebido()")
    #         st.session_state['input'] = "‚å®Ô∏è"
    #         transcreve_video_recebido()

    #     st.markdown(
    #         '_O Chat de Conversas pode cometer erros. Considere verificar informa√ß√µes importantes._')

    #     # Se houver entrada, processa a mensagem
    #     if prompt:
    #         if st.session_state['api_key'] == '':
    #             st.error('Adicione uma chave de API na aba de configura√ß√µes')
    #         else:
    #             # Exibe imediatamente a mensagem do usu√°rio no hist√≥rico
    #             st.chat_message('user').markdown(
    #                 f"<div class='user-message'>{prompt}</div>",
    #                 unsafe_allow_html=True
    #             )

    #             # Cria um placeholder para a resposta do assistente
    #             assistant_placeholder = st.chat_message('assistant').empty()
    #             resposta_acumulada = ""

    #             # Chama nova_mensagem() para obter os chunks de resposta
    #             for chunk in nova_mensagem(prompt, mensagens):
    #                 resposta_acumulada += chunk
    #                 # Atualiza o placeholder com o texto parcial e o cursor ()
    #                 assistant_placeholder.markdown(
    #                     f"<div class='assistant-message'>{resposta_acumulada}</div>",
    #                     unsafe_allow_html=True
    #                 )
    #             # Exibe a resposta final sem o cursor
    #             assistant_placeholder.markdown(
    #                 f"<div class='assistant-message'>{resposta_acumulada}</div>",
    #                 unsafe_allow_html=True
    #             )

    # ---

    # st.header('üó®Ô∏è Chat de Conversas - LLM', divider=True)

    # # Carrega o hist√≥rico de mensagens
    # mensagens = ler_mensagens(st.session_state['mensagens'])

    # # Cria um container para exibir o hist√≥rico de conversas
    # chat_container = st.container()

    # # Fun√ß√£o para renderizar as mensagens no container
    # def renderiza_chat():
    #     chat_container.empty()  # Limpa o container antes de re-renderizar
    #     for mensagem in mensagens:
    #         if mensagem['role'] == 'user':
    #             st.chat_message('user').markdown(
    #                 f'<div class="user-message">{mensagem["content"]}</div>',
    #                 unsafe_allow_html=True
    #             )
    #         else:
    #             st.chat_message('assistant').markdown(
    #                 f'<div class="assistant-message">{mensagem["content"]}</div>',
    #                 unsafe_allow_html=True
    #             )

    # # Renderiza o hist√≥rico inicial
    # renderiza_chat()

    # # √Årea de entrada (rodap√©) ‚Äì ficar√° fixa na parte inferior da tela.
    # with st.container(key='footer'):
    #     prompt = st.chat_input('Fale com o tutor')

    #     options_pills = ["‚å®Ô∏è", "üé§", "üìΩÔ∏è"]
    #     seleciona_midia = st.pills(
    #         "Selecione a M√≠dia",
    #         options_pills,
    #         selection_mode="single",
    #         key='input-select',
    #         label_visibility="hidden"
    #     )
    #     st.session_state['input'] = seleciona_midia
    #     js_debug(st.session_state['input'])

    #     # Verificar a sele√ß√£o para abrir o di√°logo correspondente
    #     if st.session_state['input'] == "‚å®Ô∏è":
    #         js_debug("reinicia o modal")
    #         st.session_state['show_modal'] = True
    #         st.session_state['transcricao'] = ''
    #     elif st.session_state['input'] == "üé§" and st.session_state['show_modal']:
    #         js_debug("transcreve_audio_recebido()")
    #         st.session_state['input'] = "‚å®Ô∏è"
    #         transcreve_audio_recebido()
    #     elif st.session_state['input'] == "üìΩÔ∏è" and st.session_state['show_modal']:
    #         js_debug("transcreve_video_recebido()")
    #         st.session_state['input'] = "‚å®Ô∏è"
    #         transcreve_video_recebido()

    #     st.markdown(
    #         '_O Chat de Conversas pode cometer erros. Considere verificar informa√ß√µes importantes._')

    #     # Processa a requisi√ß√£o se houver entrada
    #     if prompt:
    #         # Primeiro, renderiza o prompt dentro do container para que a resposta
    #         # seja exibida logo abaixo dele durante o stream.
    #         with chat_container:
    #             st.chat_message('user').markdown(
    #                 f'<div class="user-message">{prompt}</div>',
    #                 unsafe_allow_html=True
    #             )
    #         if st.session_state['api_key'] == '':
    #             st.error('Adicione uma chave de API na aba de configura√ß√µes')
    #         else:
    #             # Chama a fun√ß√£o que envia a mensagem e obt√©m a resposta,
    #             # passando o container de chat para atualiza√ß√£o
    #             nova_mensagem(prompt, mensagens, True, chat_container)
    #             # Atualiza o hist√≥rico (se a fun√ß√£o nova_mensagem modificar as mensagens)
    #             renderiza_chat()

    # ---

    # st.header('üó®Ô∏è Chat de Conversas - LLM', divider=True)

    # # 1. Carrega as mensagens do estado (ou de onde voc√™ as estiver salvando)
    # mensagens = ler_mensagens(st.session_state['mensagens'])

    # # 2. Exibe todo o hist√≥rico anterior (usu√°rio e assistente)
    # for mensagem in mensagens:
    #     if mensagem['role'] == 'user':
    #         chat = st.chat_message('user')
    #         chat.markdown(
    #             f'<div class="user-message">{mensagem["content"]}</div>',
    #             unsafe_allow_html=True
    #         )
    #     else:
    #         chat = st.chat_message('assistant')
    #         chat.markdown(
    #             f'<div class="assistant-message">{mensagem["content"]}</div>',
    #             unsafe_allow_html=True
    #         )

    # # 3. Campo de entrada (fixado no rodap√©, por padr√£o do st.chat_input)
    # prompt = st.chat_input('Converse com a Intelig√™ncia Artificial')

    # # 4. Op√ß√µes de m√≠dia (pills)
    # options_pills = ["‚å®Ô∏è", "üé§", "üìΩÔ∏è"]
    # seleciona_midia = st.pills(
    #     "Selecione a M√≠dia",
    #     options_pills,
    #     selection_mode="single",
    #     key='input-select',
    #     label_visibility="hidden"
    # )
    # st.session_state['input'] = seleciona_midia
    # js_debug(st.session_state['input'])

    # if st.session_state['input'] == "‚å®Ô∏è":
    #     js_debug("reinicia o modal")
    #     st.session_state['show_modal'] = True
    #     st.session_state['transcricao'] = ''
    # elif st.session_state['input'] == "üé§" and st.session_state['show_modal']:
    #     js_debug("transcreve_audio_recebido()")
    #     st.session_state['input'] = "‚å®Ô∏è"
    #     transcreve_audio_recebido()
    # elif st.session_state['input'] == "üìΩÔ∏è" and st.session_state['show_modal']:
    #     js_debug("transcreve_video_recebido()")
    #     st.session_state['input'] = "‚å®Ô∏è"
    #     transcreve_video_recebido()

    # st.markdown(
    #     '_O Chat de Conversas pode cometer erros. Considere verificar informa√ß√µes importantes._'
    # )

    # # 5. Se o usu√°rio digitou algo
    # if prompt:
    #     # Verifica se a chave de API est√° configurada
    #     if st.session_state['api_key'] == '':
    #         st.error('Adicione uma chave de API na aba de configura√ß√µes')
    #     else:
    #         # Chama a fun√ß√£o 'nova_mensagem' para lidar com streaming e atualizar o hist√≥rico
    #         nova_mensagem(prompt, mensagens, True, placeholder=None)
    #         # A fun√ß√£o 'nova_mensagem' j√° faz:
    #         #  - Exibir a mensagem do usu√°rio
    #         #  - Exibir placeholder do assistente
    #         #  - Fazer streaming do texto
    #         #  - Ao final, chamar 'st.rerun()' para recarregar a p√°gina

    # ----

    # st.header('üó®Ô∏è Chat de Conversas - LLM', divider=True)

    # mensagens = ler_mensagens(st.session_state['mensagens'])

    # # Cria um container para exibir o hist√≥rico de conversas.
    # chat_container = st.container()

    # # Fun√ß√£o para renderizar as mensagens no container
    # def renderiza_chat():
    #     chat_container.empty()  # Limpa o container antes de re-renderizar
    #     for mensagem in mensagens:
    #         # Aqui usamos 'role' (certifique-se de que todas as mensagens usem a mesma chave)
    #         if mensagem['role'] == 'user':
    #             st.chat_message(mensagem['role']).markdown(
    #                 f'<div class="user-message">{mensagem["content"]}</div>',
    #                 unsafe_allow_html=True
    #             )
    #         else:
    #             st.chat_message(mensagem['role']).markdown(
    #                 f'<div class="assistant-message">{mensagem["content"]}</div>',
    #                 unsafe_allow_html=True
    #             )

    # # Renderiza o hist√≥rico inicial
    # renderiza_chat()

    # # √Årea de entrada (rodap√©) ‚Äì ficar√° fixa na parte inferior da tela.
    # with st.container(key='footer'):
    #     prompt = st.chat_input('Fale com o tutor')

    #     options_pills = ["‚å®Ô∏è", "üé§", "üìΩÔ∏è"]

    #     seleciona_midia = st.pills(
    #         "Selecione a M√≠dia",
    #         options_pills,
    #         selection_mode="single",
    #         key='input-select',
    #         label_visibility="hidden"
    #     )

    #     st.session_state['input'] = seleciona_midia
    #     js_debug(st.session_state['input'])

    #     # Verificar a sele√ß√£o para abrir o di√°logo correspondente
    #     if st.session_state['input'] == "‚å®Ô∏è":
    #         js_debug("reinicia o modal")
    #         st.session_state['show_modal'] = True
    #         st.session_state['transcricao'] = ''
    #     elif st.session_state['input'] == "üé§" and st.session_state['show_modal']:
    #         js_debug("transcreve_audio_recebido()")
    #         st.session_state['input'] = "‚å®Ô∏è"
    #         transcreve_audio_recebido()
    #     elif st.session_state['input'] == "üìΩÔ∏è" and st.session_state['show_modal']:
    #         js_debug("transcreve_video_recebido()")
    #         st.session_state['input'] = "‚å®Ô∏è"
    #         transcreve_video_recebido()

    #     st.markdown(
    #         '_O Chat de Conversas pode cometer erros. Considere verificar informa√ß√µes importantes._'
    #     )

    #     # Processa a requisi√ß√£o se houver entrada
    #     if prompt:
    #         renderiza_chat()
    #         if st.session_state['api_key'] == '':
    #             st.error('Adicione uma chave de API na aba de configura√ß√µes')
    #         else:
    #             # Chama a fun√ß√£o que envia a mensagem e obt√©m a resposta,
    #             # passando o container de chat para atualiza√ß√£o
    #             nova_mensagem(prompt, mensagens, True, chat_container)
    #             # Atualiza o hist√≥rico (mensagens pode ter sido modificado pela nova mensagem)
    #             renderiza_chat()

    # placeholder = st.empty()

    # for mensagem in mensagens:
    #     if mensagem['role'] == 'user':
    #         chat = st.chat_message(mensagem['role'])
    #         chat.markdown(
    #             f'<div class="user-message">{mensagem["content"]}</div>', unsafe_allow_html=True)
    #     else:
    #         chat = st.chat_message(mensagem['role'])
    #         chat.markdown(
    #             f'<div class="assistant-message">{mensagem["content"]}</div>', unsafe_allow_html=True)

    # with st.container(key='footer'):
    #     prompt = st.chat_input('Fale com o tutor')

    #     options_pills = ["‚å®Ô∏è", "üé§", "üìΩÔ∏è"]

    #     seleciona_midia = st.pills(
    #         "Selecione a M√≠dia",
    #         options_pills,
    #         selection_mode="single",
    #         key='input-select',
    #         label_visibility="hidden"
    #     )

    #     st.session_state['input'] = seleciona_midia

    #     js_debug(st.session_state['input'])

    #     # Verificar a sele√ß√£o para abrir o di√°logo correspondente
    #     if st.session_state['input'] == "‚å®Ô∏è":
    #         js_debug("reinicia o modal")
    #         # reseta
    #         st.session_state['show_modal'] = True
    #         st.session_state['transcricao'] = ''
    #     elif st.session_state['input'] == "üé§" and st.session_state['show_modal']:
    #         js_debug("transcreve_audio_recebido()")
    #         st.session_state['input'] = "‚å®Ô∏è"
    #         transcreve_audio_recebido()
    #     elif st.session_state['input'] == "üìΩÔ∏è" and st.session_state['show_modal']:
    #         js_debug("transcreve_video_recebido()")
    #         st.session_state['input'] = "‚å®Ô∏è"
    #         transcreve_video_recebido()

    #     st.markdown(
    #         '_O Chat de Conversas pode cometer erros. Considere verificar informa√ß√µes importantes._')

    #     # Faz a requisi√ß√£o, se houver
    #     if prompt:
    #         if st.session_state['api_key'] == '':
    #             st.error('Adicone uma chave de api na aba de configura√ß√µes')
    #         else:
    #             nova_mensagem(prompt, mensagens, True, placeholder)


# P√°gina de Configura√ß√µes =========================

def config_page() -> None:
    """
    Exibe a p√°gina de configura√ß√µes do chatbot, permitindo modificar par√¢metros do modelo de IA.

    Opera√ß√µes:
    \n\t- Exibe os campos de entrada para altera√ß√£o do modelo de IA.
    \n\t- Permite modificar o tipo de busca e par√¢metros de recupera√ß√£o de informa√ß√µes.
    \n\t- Exibe e permite a edi√ß√£o do prompt base utilizado pelo chatbot.
    \n\t- Atualiza os valores na sess√£o do Streamlit e reinicia o chatbot se necess√°rio.

    Retorno:
    \n\t`None`: Apenas exibe a interface e atualiza os valores de configura√ß√£o no Streamlit.

    Exemplo:
    >>> config_page()
    """
    st.header('üìë - RAG Config', divider=True)

    model = st.text_input('Modifique o modelo',
                          value=get_config('modelo'))

    retrieval_search_type = st.text_input('Modifique o tipo de retrieval',
                                          value=get_config('retrieval_search_type'))

    retrieval_kwargs = st.text_input('Modifique os par√¢metros de retrieval',
                                     value=json.dumps(get_config('retrieval_kwargs')))

    prompt = st.text_area('Modifique o prompt padr√£o',
                          height=300,
                          value=get_config('prompt'))

    if st.button('Salvar par√¢metros', use_container_width=True):
        retrieval_kwargs = json.loads(retrieval_kwargs.replace("'", '"'))
        st.session_state['modelo'] = model
        st.session_state['retrieval_search_type'] = retrieval_search_type
        st.session_state['retrieval_kwargs'] = retrieval_kwargs
        st.session_state['prompt'] = prompt
        st.info('Par√¢metros salvos com sucesso!')
        st.rerun()

    if st.button('Atualizar o ATI', use_container_width=True):
        if len(list(PASTA_ARQUIVOS.glob('*.pdf'))) == 0:
            st.error(
                'Adicione arquivos .pdf para inicializar o ATI (Agente Tutor Inteligente)')
        else:
            st.success('Inicializando o ATI (Agente Tutor Inteligente)...')
            cria_chain_conversa()
            st.rerun()


# P√°gina de Tutoria =========================

def pg_tutoria() -> None:
    """
    Exibe a p√°gina de tutoria do chatbot, permitindo intera√ß√µes com documentos previamente carregados.

    Opera√ß√µes:
    \n\t- Exibe um cabe√ßalho e um aviso se nenhum documento for carregado.
    \n\t- Recupera o hist√≥rico de conversas do chatbot e exibe as mensagens.
    \n\t- Permite ao usu√°rio interagir com o chatbot enviando novas mensagens.
    \n\t- Exibe respostas do chatbot com base nos documentos processados.

    Retorno:
    \n\t`None`: Apenas exibe a interface e processa as intera√ß√µes no Streamlit.

    Exemplo:
    >>> pg_tutoria()
    """
    st.header('üéì ATI - Agente Tutor Inteligente', divider=True)

    if not 'chain' in st.session_state or st.session_state['chain'] == '':
        st.error('Fa√ßa o upload de PDFs para come√ßar!')
    else:
        chain = st.session_state['chain']
        memory = chain.memory

        mensagens = memory.load_memory_variables({})['chat_history']

        container = st.container()
        for mensagem in mensagens:
            chat = container.chat_message(mensagem.type)
            chat.markdown(mensagem.content)

        nova_mensagem = st.chat_input(
            'Converse com o seu Agente Tutor Inteligente...')
        if nova_mensagem:
            chat = container.chat_message('human')
            chat.markdown(nova_mensagem)
            chat = container.chat_message('ai')
            # chat.markdown('‚ñå ')  # Gerando resposta
            chat.markdown("<span>‚ñå</span>", unsafe_allow_html=True)

            resposta = chain.invoke({'question': nova_mensagem})
            st.session_state['ultima_resposta'] = resposta
            st.rerun()


# P√°gina de Tutoria =========================

# def pg_tutoria() -> None:
#     """
#     Exibe a p√°gina de tutoria do chatbot, permitindo intera√ß√µes com documentos previamente carregados.

#     Opera√ß√µes:
#     \n\t- Exibe um cabe√ßalho e um aviso se nenhum documento for carregado.
#     \n\t- Recupera o hist√≥rico de conversas do chatbot e exibe as mensagens.
#     \n\t- Permite ao usu√°rio interagir com o chatbot enviando novas mensagens.
#     \n\t- Exibe respostas do chatbot com base nos documentos processados.

#     Retorno:
#     \n\t`None`: Apenas exibe a interface e processa as intera√ß√µes no Streamlit.

#     Exemplo:
#     >>> pg_tutoria()
#     """
#     # st.header('üéì ATI - Agente Tutor Inteligente', divider=True)

#     # if not 'chain' in st.session_state or st.session_state['chain'] == '':
#     #     st.error('Fa√ßa o upload de PDFs para come√ßar!')
#     # else:
#     #     chain = st.session_state['chain']
#     st.header('üéì ATI - Agente Tutor Inteligente', divider=True)

#     if 'chain' not in st.session_state or not st.session_state['chain']:
#         st.error('Fa√ßa o upload de PDFs para come√ßar!')
#         return

#     chain = st.session_state['chain']
#     memory = chain.memory
#     # Carrega o hist√≥rico de conversas do LangChain
#     mensagens = memory.load_memory_variables({})['chat_history']

#     # Inicializa o hist√≥rico de mensagens, se ainda n√£o estiver definido
#     if 'mensagens' not in st.session_state:
#         st.session_state['mensagens'] = mensagens

#     # Container para exibir o hist√≥rico de mensagens
#     # container = st.container()
#     # for mensagem in mensagens:
#     #     chat = container.chat_message(mensagem.type)
#     #     chat.markdown(mensagem.content)

#     # O campo de entrada do chat fica fixo no rodap√© da p√°gina
#     # nova_mensagem = st.chat_input(
#     #     'Converse com o seu Agente Tutor Inteligente...')

#     # Container para exibir o hist√≥rico de mensagens
#     chat_container = st.container()
#     with chat_container:
#         for mensagem in st.session_state['mensagens']:
#             # st.chat_message(mensagem.type).markdown(mensagem.content)
#             st.chat_message(mensagem["type"]).markdown(mensagem["content"])

#     # O campo de entrada do chat fica fixo no rodap√© da p√°gina
#     nova_mensagem = st.chat_input(
#         'Converse com o seu Agente Tutor Inteligente...')

#     # if nova_mensagem:
#     #     chat = container.chat_message('human')
#     #     chat.markdown(nova_mensagem)
#     #     chat = container.chat_message('ai')
#     #     chat.markdown('‚ñå ')  # Gerando resposta

#     #     resposta = chain.invoke({'question': nova_mensagem})
#     #     st.session_state['ultima_resposta'] = resposta
#     #     st.rerun()

#     if nova_mensagem:
#         # Exibe a mensagem do usu√°rio no container (acima do input)
#         mensagem_usuario = {'type': 'human', 'content': nova_mensagem}
#         st.session_state['mensagens'].append(mensagem_usuario)

#         # Atualiza a mensagem enviada pelo usu√°rio
#         with chat_container:
#             st.chat_message('human').markdown(nova_mensagem)

#         # Cria um placeholder para a resposta do assistente (tamb√©m no container)
#         with chat_container:
#             ai_placeholder = st.chat_message('ai').empty()
#             ai_placeholder.markdown('‚ñå')

#         # Obt√©m a resposta do assistente
#         resposta = chain.invoke({'question': nova_mensagem})
#         resposta_texto = resposta.get('answer', 'Desculpe, ocorreu um erro.')

#         # Atualiza o placeholder com a resposta final
#         ai_placeholder.markdown(resposta_texto)

#         # Armazena a resposta no hist√≥rico
#         mensagem_ai = {'type': 'ai', 'content': resposta_texto}
#         st.session_state['mensagens'].append(mensagem_ai)

    """
    Divisor
    """
    # st.header('üéì ATI - Agente Tutor Inteligente', divider=True)

    # if not 'chain' in st.session_state or st.session_state['chain'] == '':
    #     st.error('Fa√ßa o upload de PDFs para come√ßar!')
    # else:
    #     chain = st.session_state['chain']
    #     memory = chain.memory

    #     # Carrega o hist√≥rico de conversas do LangChain
    #     mensagens = memory.load_memory_variables({})['chat_history']

    #     container = st.container()
    #     # Exibe todas as mensagens anteriores
    #     for mensagem in mensagens:
    #         chat = container.chat_message(mensagem.type)
    #         chat.markdown(mensagem.content)

    #     # Caixa de input do usu√°rio
    #     nova_mensagem = st.chat_input(
    #         'Converse com o seu Agente Tutor Inteligente...'
    #     )
    #     if nova_mensagem:
    #         # Exibe a mensagem do usu√°rio imediatamente
    #         chat_user = container.chat_message('human')
    #         chat_user.markdown(nova_mensagem)

    #         # Placeholder para a resposta do AI
    #         chat_ai = container.chat_message('ai')
    #         # chat.markdown('‚ñå ')  # Gerando resposta
    #         placeholder = chat_ai.empty()
    #         placeholder.markdown('‚ñå')  # Pode deixar esse cursor, se quiser

    #         # Invoca a chain para obter a resposta
    #         resposta = chain.invoke({'question': nova_mensagem})

    #         # Atualiza o placeholder com a resposta final
    #         placeholder.markdown(resposta['answer'])

    #         # Armazena a √∫ltima resposta se for preciso
    #         st.session_state['ultima_resposta'] = resposta

    # A mem√≥ria do LangChain atualiza automaticamente,
    # mas, se precisar, voc√™ pode atualizar o st.session_state tamb√©m.
    # Se quiser exibir a conversa sem recarregar, basta n√£o chamar st.rerun().
    # Se precisar recarregar por algum outro motivo, chame st.rerun() aqui
    # mas saiba que isso far√° o app redesenhar tudo.

    """
    Exibe a p√°gina de tutoria do chatbot.
    O hist√≥rico de mensagens √© exibido em um container acima,
    e o st.chat_input() permanece fixado no rodap√©.
    """
    # st.header('üéì ATI - Agente Tutor Inteligente', divider=True)

    # if 'chain' not in st.session_state or not st.session_state['chain']:
    #     st.error('Fa√ßa o upload de PDFs para come√ßar!')
    #     return

    # chain = st.session_state['chain']

    # # Inicializa o hist√≥rico de mensagens, se ainda n√£o estiver definido
    # if 'mensagens' not in st.session_state:
    #     st.session_state['mensagens'] = chain.memory.load_memory_variables({})[
    #         'chat_history']

    # # Container para exibir o hist√≥rico de mensagens
    # chat_container = st.container()
    # with chat_container:
    #     for mensagem in st.session_state['mensagens']:
    #         st.chat_message(mensagem.type).markdown(mensagem.content)

    # # O campo de entrada do chat fica fixo no rodap√© da p√°gina
    # nova_mensagem = st.chat_input(
    #     'Converse com o seu Agente Tutor Inteligente...')
    # if nova_mensagem:
    #     # Exibe a mensagem do usu√°rio no container (acima do input)
    #     mensagem_usuario = {'type': 'human', 'content': nova_mensagem}
    #     st.session_state['mensagens'].append(mensagem_usuario)
    #     with chat_container:
    #         st.chat_message('human').markdown(nova_mensagem)

    #     # Cria um placeholder para a resposta do assistente (tamb√©m no container)
    #     with chat_container:
    #         ai_placeholder = st.chat_message('ai').empty()
    #         ai_placeholder.markdown('‚ñå')

    #     # Obt√©m a resposta do assistente
    #     resposta = chain.invoke({'question': nova_mensagem})
    #     resposta_texto = resposta.get('answer', 'Desculpe, ocorreu um erro.')

    #     # Atualiza o placeholder com a resposta final
    #     ai_placeholder.markdown(resposta_texto)

    #     # Armazena a resposta no hist√≥rico
    #     mensagem_ai = {'type': 'ai', 'content': resposta_texto}
    #     st.session_state['mensagens'].append(mensagem_ai)


# P√°gina de An√°lise =========================

def pg_analise() -> None:
    """
    Exibe a p√°gina de an√°lise e depura√ß√£o das intera√ß√µes do chatbot.

    Opera√ß√µes:
    \n\t- Exibe um cabe√ßalho para a se√ß√£o de an√°lise.
    \n\t- Recupera a √∫ltima resposta gerada pelo chatbot.
    \n\t- Exibe o hist√≥rico de conversas e os documentos utilizados no contexto da resposta.
    \n\t- Mostra o prompt final gerado pelo modelo antes de processar a resposta.

    Retorno:
    \n\t`None`: Apenas exibe a interface e apresenta os detalhes da an√°lise.

    Exemplo:
    >>> pg_analise()
    """

    st.header('üìá P√°gina de debug', divider=True)

    prompt_template = get_config('prompt')
    prompt_template = PromptTemplate.from_template(prompt_template)

    if 'ultima_resposta' not in st.session_state or st.session_state['ultima_resposta'] == '':
        st.error('Realize uma pergunta para o modelo para visualizar o debug')
    else:
        ultima_resposta = st.session_state['ultima_resposta']

        contexto_docs = ultima_resposta['source_documents']
        contexto_list = [doc.page_content for doc in contexto_docs]
        contexto_str = '\n\n'.join(contexto_list)

        chain = st.session_state['chain']
        memory = chain.memory
        chat_history = memory.buffer_as_str

        with st.container(border=True):
            prompt = prompt_template.format(
                chat_history=chat_history,
                context=contexto_str,
                question=''
            )
            st.code(prompt)


# body {
#     margin: 0px;
#     font-family: "Source Sans Pro", sans-serif;
#     font-weight: 400;
#     line-height: 1.6;
#     color: rgb(49, 51, 63);
#     background-color: rgb(255, 255, 255);
#     text-size-adjust: 100%;
#     -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
#     -webkit-font-smoothing: auto;
# }

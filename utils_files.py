# --- File: utils_file.py --- #

# --- Libraries --- #
import streamlit as st  # Framework para criar interfaces web interativas.
import os  # Biblioteca para manipula√ß√£o de arquivos e vari√°veis de ambiente.
import re  # Biblioteca para express√µes regulares.
# Biblioteca para serializa√ß√£o e desserializa√ß√£o de objetos Python.
import pickle
import json  # Biblioteca para manipula√ß√£o de arquivos JSON.
import requests  # Biblioteca para fazer requisi√ß√µes HTTP.
import pydub  # Biblioteca para manipula√ß√£o de arquivos de √°udio.

# Remove acentos e caracteres especiais de strings.
from unidecode import unidecode
from pathlib import Path  # Manipula√ß√£o de caminhos de arquivos e diret√≥rios.

# Bibliotecas do LangChain para processamento de linguagem natural e recupera√ß√£o de documentos.
# Implementa√ß√£o de um fluxo de recupera√ß√£o conversacional de informa√ß√µes.
from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain
# Armazena o hist√≥rico da conversa para ser reutilizado durante a intera√ß√£o.
from langchain.memory import ConversationBufferMemory
# Permite a cria√ß√£o de templates para estruturar prompts usados nos modelos de IA.
from langchain.prompts import PromptTemplate
# Carrega e processa documentos PDF para serem utilizados na recupera√ß√£o de informa√ß√µes.
from langchain_community.document_loaders.pdf import PyPDFLoader
# Utiliza a biblioteca FAISS para armazenar e recuperar embeddings de documentos.
from langchain_community.vectorstores.faiss import FAISS
# Divide textos longos em segmentos menores de maneira recursiva para otimizar a recupera√ß√£o de informa√ß√µes.
from langchain_text_splitters import RecursiveCharacterTextSplitter
# Gera embeddings de texto usando modelos da OpenAI.
from langchain_openai.embeddings import OpenAIEmbeddings
# Implementa um modelo de chat baseado na OpenAI para gera√ß√£o de respostas contextuais.
from langchain_openai.chat_models import ChatOpenAI

# Biblioteca para carregar vari√°veis de ambiente do arquivo .env.
from dotenv import load_dotenv, find_dotenv
from configs import *  # Importa configura√ß√µes do sistema.
from assets import *  # Importa estilos e scripts auxiliares.
from moviepy import *  # Biblioteca para manipula√ß√£o de v√≠deos.
# Importa fun√ß√µes auxiliares para integra√ß√£o com OpenAI.
from utils_openai import *
from io import BytesIO  # Biblioteca para manipula√ß√£o de fluxos de bytes.

# --- Environment Setup --- #
# Carrega o arquivo .env que cont√©m as credenciais sens√≠veis.
_ = load_dotenv(find_dotenv())

# Obt√©m a chave da API da OpenAI.
api_key = os.getenv("OPENAI_API_KEY")


# --- Directory Setup --- #
PASTA_CONFIGERACOES = Path(__file__).parent / 'configuracoes'
PASTA_CONFIGERACOES.mkdir(exist_ok=True)
PASTA_MENSAGENS = Path(__file__).parent / 'mensagens'
PASTA_MENSAGENS.mkdir(exist_ok=True)
PASTA_ARQUIVOS = Path(__file__).parent / 'arquivos'
PASTA_ARQUIVOS.mkdir(exist_ok=True)
PASTA_TEMP = Path(__file__).parent / 'temp'
PASTA_TEMP.mkdir(exist_ok=True)

# Arquivos tempor√°rios
ARQUIVO_AUDIO_TEMP = PASTA_TEMP / 'audio.mp3'
ARQUIVO_MIC_TEMP = PASTA_TEMP / 'mic.mp3'
ARQUIVO_VIDEO_TEMP = PASTA_TEMP / 'video.mp4'
ARQUIVO_FOTO_TEMP = PASTA_TEMP / 'foto.jpeg'

# Cache para otimizar convers√µes
CACHE_DESCONVERTE = {}


# --- Methods --- #
# SALVAMENTO E LEITURA DE CONVERSAS ========================

def converte_nome_mensagem(nome_mensagem: str) -> str:
    """
    Converte o nome da mensagem para um formato adequado para uso como nome de arquivo.

    Par√¢metros:
    \n\t`nome_mensagem (str)`: O nome da mensagem a ser convertido.

    Retorno:
    \n\t`str`: Nome da mensagem convertido, sem acentos e caracteres especiais, em min√∫sculas.
    """
    nome_arquivo = unidecode(nome_mensagem)
    nome_arquivo = re.sub(r'\W+', '', nome_arquivo).lower()
    return nome_arquivo


def desconverte_nome_mensagem(nome_arquivo: str) -> str:
    """
    Obt√©m o nome original da mensagem a partir do nome do arquivo.

    Par√¢metros:
    \n\t`nome_arquivo (str)`: O nome do arquivo.

    Retorno:
    \n\t`str`: Nome original associado ao arquivo.
    """
    if not nome_arquivo in CACHE_DESCONVERTE:
        nome_mensagem = ler_mensagem_por_nome_arquivo(
            nome_arquivo, key='nome_mensagem')
        CACHE_DESCONVERTE[nome_arquivo] = nome_mensagem
    return CACHE_DESCONVERTE[nome_arquivo]


def retorna_nome_da_mensagem(mensagens: list) -> str:
    """
    Retorna o nome da mensagem com base na primeira mensagem enviada pelo usu√°rio.

    Par√¢metros:
    \n\t`mensagens (list)`: Lista de mensagens contendo dicion√°rios com chaves 'role' e 'content'.

    Retorno:
    \n\t`str`: Conte√∫do da primeira mensagem do usu√°rio, limitado aos primeiros 30 caracteres.

    Exemplo:
    >>> mensagens = [{"role": "user", "content": "Este √© um exemplo de mensagem longa."}]
    >>> retorna_nome_da_mensagem(mensagens)
    "Este √© um exemplo de mensagem longa."
    """
    nome_mensagem = ''
    for mensagem in mensagens:
        if mensagem['role'] == 'user':
            nome_mensagem = mensagem['content'][:30]
            break
    return nome_mensagem


def salvar_mensagens(mensagens: list) -> bool:
    """
    Salva uma lista de mensagens em um arquivo utilizando `pickle`.

    Par√¢metros:
    \n\t`mensagens (list)`: Lista de mensagens contendo dicion√°rios com chaves 'role' e 'content'.

    Retorno:
    \n\t`bool`: Retorna `False` se a lista de mensagens estiver vazia; caso contr√°rio, salva e retorna `True`.

    Exemplo:
    >>> mensagens = [{"role": "user", "content": "Ol√°!"}]
    >>> salvar_mensagens(mensagens)
    True
    """
    if len(mensagens) == 0:
        return False
    nome_mensagem = retorna_nome_da_mensagem(mensagens)
    nome_arquivo = converte_nome_mensagem(nome_mensagem)
    arquivo_salvar = {
        'nome_mensagem': nome_mensagem,
        'nome_arquivo': nome_arquivo,
        'mensagem': mensagens
    }
    with open(PASTA_MENSAGENS / nome_arquivo, 'wb') as f:
        pickle.dump(arquivo_salvar, f)
    return True


def ler_mensagem_por_nome_arquivo(nome_arquivo: str, key: str = 'mensagem'):
    """
    L√™ uma mensagem salva a partir do nome do arquivo.

    Par√¢metros:
    \n\t`nome_arquivo (str)`: Nome do arquivo contendo a mensagem salva.
    \n\t`key (str)`: Chave espec√≠fica dentro do dicion√°rio salvo para ser retornada (padr√£o: 'mensagem').

    Retorno:
    \n\t`dict | str`: Conte√∫do correspondente √† chave especificada dentro do arquivo salvo.

    Exemplo:
    >>> ler_mensagem_por_nome_arquivo('exemplo_mensagem')
    [{"role": "user", "content": "Ol√°!"}]
    """
    with open(PASTA_MENSAGENS / nome_arquivo, 'rb') as f:
        mensagens = pickle.load(f)
    return mensagens[key]


def ler_mensagens(mensagens: list, key: str = 'mensagem') -> list:
    """
    L√™ mensagens a partir de uma lista fornecida, recuperando os dados armazenados em arquivos.

    Par√¢metros:
    \n\t`mensagens (list)`: Lista contendo mensagens em formato de dicion√°rio com as chaves 'role' e 'content'.
    \n\t`key (str)`: Chave do dicion√°rio armazenado para retornar a informa√ß√£o desejada (padr√£o: 'mensagem').

    Retorno:
    \n\t`list`: Lista de mensagens lidas do arquivo correspondente ou uma lista vazia se nenhum dado for encontrado.

    Exemplo:
    >>> mensagens = [{"role": "user", "content": "Ol√°!"}]
    >>> ler_mensagens(mensagens)
    [{"role": "user", "content": "Ol√°!"}]
    """
    if len(mensagens) == 0:
        return []
    nome_mensagem = retorna_nome_da_mensagem(mensagens)
    nome_arquivo = converte_nome_mensagem(nome_mensagem)
    with open(PASTA_MENSAGENS / nome_arquivo, 'rb') as f:
        mensagens = pickle.load(f)
    return mensagens[key]


def listar_conversas() -> list:
    """
    Lista todas as conversas salvas, ordenadas pela √∫ltima modifica√ß√£o.

    Retorno:
    \n\t`list`: Lista dos nomes das conversas armazenadas, ordenadas da mais recente para a mais antiga.

    Exemplo:
    >>> listar_conversas()
    ['conversa1', 'conversa2']
    """
    conversas = list(PASTA_MENSAGENS.glob('*'))
    conversas = sorted(
        conversas, key=lambda item: item.stat().st_mtime_ns, reverse=True)
    return [c.stem for c in conversas]


# SALVAMENTO E LEITURA DA APIKEY ========================

def salva_chave(chave: str) -> None:
    """
    Salva a chave da API da OpenAI em um arquivo utilizando serializa√ß√£o com `pickle`.

    Par√¢metros:
    \n\t`chave (str)`: Chave da API a ser salva.

    Exemplo:
    >>> salva_chave("sk-12345ABCDE67890FGHIJ")
    """
    with open(PASTA_CONFIGERACOES / 'chave', 'wb') as f:
        pickle.dump(chave, f)


def le_chave() -> str:
    """
    L√™ a chave da API salva em um arquivo ou do arquivo .env.

    Retorno:
    \n\t`str`: Chave lida do arquivo ou do ambiente. Retorna uma string vazia se n√£o for encontrada.

    Exemplo:
    >>> le_chave()
    'sk-12345ABCDE67890FGHIJ'
    """
    if (PASTA_CONFIGERACOES / 'chave').exists():
        with open(PASTA_CONFIGERACOES / 'chave', 'rb') as f:
            return pickle.load(f)
    else:
        # Obt√©m a chave da API do arquivo .env
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            return api_key
        else:
            return ''


# RAG com LANGCHAIN ========================

def importacao_documentos() -> list:
    """
    Carrega documentos PDF da pasta de arquivos e os transforma em uma lista de documentos process√°veis.

    Retorno:
    \n\t`list`: Lista de documentos carregados a partir dos arquivos PDF dispon√≠veis.

    Exemplo:
    >>> documentos = importacao_documentos()
    >>> print(len(documentos))
    5
    """
    documentos = []
    for arquivo in PASTA_ARQUIVOS.glob('*.pdf'):
        loader = PyPDFLoader(str(arquivo))
        documentos_arquivo = loader.load()
        documentos.extend(documentos_arquivo)
    return documentos


def split_de_documentos(documentos: list) -> list:
    """
    Divide documentos longos em trechos menores para facilitar a recupera√ß√£o de informa√ß√µes.

    Par√¢metros:
    \n\t`documentos (list)`: Lista de documentos a serem fragmentados.

    Retorno:
    \n\t`list`: Lista de documentos segmentados, prontos para processamento.

    Exemplo:
    >>> documentos = split_de_documentos(importacao_documentos())
    >>> print(len(documentos))
    20
    """
    recur_splitter = RecursiveCharacterTextSplitter(
        chunk_size=2500,
        chunk_overlap=250,
        separators=["/n\n", "\n", ".", " ", ""]
    )
    documentos = recur_splitter.split_documents(documentos)

    for i, doc in enumerate(documentos):
        doc.metadata['source'] = doc.metadata['source'].split('/')[-1]
        doc.metadata['doc_id'] = i
    return documentos


def cria_vector_store(documentos: list):
    """
    Cria um armazenamento vetorial utilizando FAISS a partir de uma lista de documentos segmentados.

    Par√¢metros:
    \n\t`documentos (list)`: Lista de documentos processados e divididos em trechos menores.

    Retorno:
    \n\t`FAISS`: Um √≠ndice FAISS contendo os embeddings dos documentos para recupera√ß√£o eficiente de informa√ß√µes.

    Exemplo:
    >>> documentos = split_de_documentos(importacao_documentos())
    >>> vector_store = cria_vector_store(documentos)
    >>> print(vector_store)
    <langchain_community.vectorstores.faiss.FAISS object at 0x...>
    """
    try:
        embedding_model = OpenAIEmbeddings()
        print("Embedding model initialized successfully.")
        vector_store = FAISS.from_documents(
            documents=documentos,
            embedding=embedding_model
        )
        return vector_store
    except Exception as e:
        print("Failed to initialize embedding model:", e)


def cria_chain_conversa():
    """
    Cria a cadeia de conversa√ß√£o utilizando LangChain para recupera√ß√£o de informa√ß√µes baseada em conversas anteriores e documentos fornecidos.

    Retorno:
    \n\t`None`: A fun√ß√£o n√£o retorna nada explicitamente, mas armazena a cadeia no estado da sess√£o do Streamlit.

    Exemplo:
    >>> cria_chain_conversa()
    >>> print(st.session_state['chain'])
    <langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain object at 0x...>
    """

    documentos = importacao_documentos()
    documentos = split_de_documentos(documentos)
    vector_store = cria_vector_store(documentos)

    chat = ChatOpenAI(model=get_config('modelo'))
    memory = ConversationBufferMemory(
        return_messages=True,
        memory_key='chat_history',
        output_key='answer'
    )
    retriever = vector_store.as_retriever(
        search_type=get_config('retrieval_search_type'),
        search_kwargs=get_config('retrieval_kwargs')
    )
    prompt = PromptTemplate.from_template(get_config('prompt'))
    chat_chain = ConversationalRetrievalChain.from_llm(
        llm=chat,
        memory=memory,
        retriever=retriever,
        return_source_documents=True,
        verbose=True,
        combine_docs_chain_kwargs={'prompt': prompt}
    )

    st.session_state['chain'] = chat_chain


# FUN√á√ïES ==================================================


def seleciona_conversa(nome_arquivo: str) -> None:
    """
    Seleciona uma conversa existente ou cria uma nova sess√£o de conversa.

    Par√¢metros:
    \n\t`nome_arquivo (str)`: Nome do arquivo da conversa a ser carregada. Se for uma string vazia, inicia uma nova conversa.

    Retorno:
    \n\t`None`: Atualiza o estado da sess√£o do Streamlit com a conversa selecionada.

    Exemplo:
    >>> seleciona_conversa('conversa1')
    >>> print(st.session_state['conversa_atual'])
    'conversa1'
    """
    if nome_arquivo == '':
        st.session_state['mensagens'] = []
    else:
        mensagem = ler_mensagem_por_nome_arquivo(nome_arquivo)
        st.session_state['mensagens'] = mensagem
    st.session_state['conversa_atual'] = nome_arquivo


def mascarar_chave(chave: str) -> str:
    """
    Mascarar uma chave API para exibi√ß√£o segura, ocultando parte dos caracteres.

    Par√¢metros:
    \n\t`chave (str)`: A chave API a ser mascarada.

    Retorno:
    \n\t`str`: Chave mascarada com os primeiros 5 e os √∫ltimos 5 caracteres vis√≠veis.

    Exemplo:
    >>> mascarar_chave("sk-12345ABCDE67890FGHIJ")
    'sk-12345***FGHIJ'
    """
    if len(chave) > 10:
        return chave[:5] + '***' + chave[-5:]
    else:
        return chave


def nova_mensagem(prompt: str, mensagens: list, flag: bool = False, placeholder=None) -> None:
    """
    Adiciona uma nova mensagem ao hist√≥rico de conversas e exibe a intera√ß√£o com o chatbot.

    Par√¢metros:
    \n\t`prompt (str)`: Texto da mensagem enviada pelo usu√°rio.
    \n\t`mensagens (list)`: Lista contendo o hist√≥rico das mensagens da conversa.
    \n\t`flag (bool)`: Se `True`, exibe a mensagem visualmente no chat.
    \n\t`placeholder`: Elemento do Streamlit utilizado para atualizar mensagens em tempo real.

    Retorno:
    \n\t`None`: Atualiza o estado da sess√£o do Streamlit e exibe a intera√ß√£o.

    Exemplo:
    >>> mensagens = []
    >>> nova_mensagem("Ol√°!", mensagens, True)
    """
    st.session_state['show_modal'] = False

    nova_mensagem = {'role': 'user',
                     'content': prompt}

    mensagens.append(nova_mensagem)

    if flag:
        chat = st.chat_message(nova_mensagem['role'])
        chat.markdown(
            f'<div class="user-message">{nova_mensagem["content"]}</div>', unsafe_allow_html=True)

        chat = st.chat_message('assistant')

        placeholder = chat.empty()

        placeholder.markdown(
            "<div class='assistant-message'>‚ñå </div>", unsafe_allow_html=True)

    resposta_completa = ''

    try:
        respostas = retorna_resposta_modelo(
            mensagens,
            st.session_state['api_key'],
            modelo=st.session_state['modelo'],
            stream=True,
        )

        for resposta in respostas:
            try:
                json_resposta = json.loads(
                    resposta.lstrip("data: "))

                delta = json_resposta.get("choices", [{}])[
                    0].get("delta", {})

                content = delta.get("content", "")
                resposta_completa += content

                if flag:
                    placeholder.markdown(
                        f"<div class='assistant-message'>{resposta_completa}‚ñå</div>",
                        unsafe_allow_html=True
                    )

            except json.JSONDecodeError as e:
                print("Mensagem de Stream recebida com sucesso!")
                continue

            except Exception as e:
                print(f"Erro inesperado: {e}")
                st.error(
                    "Erro inesperado ao processar a resposta.")

        if flag:
            placeholder.markdown(
                f"<div class='assistant-message'>{resposta_completa}</div>",
                unsafe_allow_html=True
            )

        nova_mensagem = {'role': 'assistant',
                         'content': resposta_completa}

        st.session_state['mensagens'] = mensagens

        mensagens.append(nova_mensagem)

        salvar_mensagens(mensagens)

        if placeholder is None:
            st.rerun()

    except requests.exceptions.HTTPError as e:
        st.error(
            'üò£ Desculpe, mas o ChatGPT est√° indispon√≠vel no momento.')
        print(f"Erro HTTP: {e}")

    except Exception as e:
        st.error(
            'üò´ Ocorreu um erro inesperado. Por favor, tente novamente mais tarde.')
        print(f"Erro inesperado: {e}")


def transcreve_audio(caminho_audio: str, prompt: str, headers: dict, _return: bool = True):
    """
    Transcreve um arquivo de √°udio utilizando a API da OpenAI (Whisper-1).

    Par√¢metros:
    \n\t`caminho_audio (str)`: Caminho do arquivo de √°udio que ser√° transcrito.
    \n\t`prompt (str)`: Sugest√£o opcional para orientar a transcri√ß√£o.
    \n\t`headers (dict)`: Cabe√ßalhos HTTP contendo a chave da API e outras configura√ß√µes.
    \n\t`_return (bool)`: Se `True`, exibe a transcri√ß√£o no Streamlit; se `False`, apenas armazena no estado da sess√£o.

    Retorno:
    \n\t`str | None`: Retorna a transcri√ß√£o do √°udio se `_return` for `True`, ou `None` caso contr√°rio.

    Exemplo:
    >>> headers = {"Authorization": "Bearer minha_api_key"}
    >>> transcricao = transcreve_audio("audio.mp3", "Transcreva este √°udio.", headers)
    >>> print(transcricao)
    "Este √© o conte√∫do do √°udio transcrito."
    """

    with open(caminho_audio, 'rb') as arquivo_audio:
        audio_bytes = arquivo_audio.read()
        # Preparar o MultipartEncoder (alternativo)
        # m = MultipartEncoder(
        #     fields={
        #         'file': ('audio.mp3', BytesIO(audio_bytes), 'audio/mpeg'),
        #         'prompt': prompt_input,
        #         'model': 'whisper-1',
        #         'language': 'pt',
        #         'response_format': 'text'
        #     }
        # )
        # headers['Content-Type'] = m.content_type
        files = {
            'file': ('audio.mp3', BytesIO(audio_bytes), 'audio/mpeg'),
            'model': (None, 'whisper-1'),
            'language': (None, 'pt'),
            'response_format': (None, 'text'),
            'prompt': (None, prompt)
        }

        response = requests.post(
            # "https://api.openai.com/v1/audio/transcriptions", headers=headers, data=m)
            "https://api.openai.com/v1/audio/transcriptions", headers=headers, files=files)

        try:
            if response.status_code == 200:
                transcricao = response.text
                st.session_state['transcricao'] = transcricao
                if _return:
                    return st.markdown(f'<div class="st-key-transcricao">{transcricao}</div><br/>', unsafe_allow_html=True)
                else:
                    return None

            else:
                print(f"Erro: {response.status_code}")
                print("Erro ao decodificar a resposta da API. Resposta:")
                print(response.text)
                return st.error(f"Erro: {response.status_code} ao decodificar a resposta da API. Veja os detalhes no terminal.")

        except ValueError:
            print(f"Erro: {response.status_code}")
            print("Erro ao decodificar a resposta da API. Resposta:")
            print(response.text)
            return st.error("Erro ao decodificar a resposta da API. Veja os detalhes no terminal.")


def adiciona_chunck_de_audio(frames_de_audio: list, chunck_audio) -> object:
    """
    Adiciona um conjunto de frames de √°udio a um segmento de √°udio existente.

    Par√¢metros:
    \n\t`frames_de_audio (list)`: Lista de frames de √°udio que ser√£o adicionados ao segmento de √°udio.
    \n\t`chunck_audio (pydub.AudioSegment)`: Segmento de √°udio onde os frames ser√£o concatenados.

    Retorno:
    \n\t`pydub.AudioSegment`: O segmento de √°udio atualizado com os frames adicionados.

    Exemplo:
    >>> from pydub import AudioSegment
    >>> chunck_audio = AudioSegment.silent(duration=1000)  # √Åudio de 1 segundo de sil√™ncio
    >>> frames = [AudioSegment.silent(duration=500), AudioSegment.silent(duration=500)]
    >>> novo_audio = adiciona_chunck_de_audio(frames, chunck_audio)
    >>> print(len(novo_audio))
    2000  # O √°udio agora tem 2 segundos de dura√ß√£o
    """
    for frame in frames_de_audio:
        sound = pydub.AudioSegment(
            data=frame.to_ndarray().tobytes(),
            sample_width=frame.format.bytes,
            frame_rate=frame.sample_rate,
            channels=len(frame.layout.channels)
        )
        chunck_audio += sound
    return chunck_audio


# TRANSCREVE VIDEO =====================================

def _salva_audio_do_video(video_bytes: BytesIO) -> str:
    """
    Extrai e salva o √°udio de um arquivo de v√≠deo.

    Par√¢metros:
    \n\t`video_bytes (BytesIO)`: Objeto contendo os bytes do v√≠deo a ser processado.

    Retorno:
    \n\t`str`: Retorna a string "Continue" ap√≥s a extra√ß√£o do √°udio ser conclu√≠da com sucesso.

    Exemplo:
    >>> with open("video.mp4", "rb") as f:
    >>>     video_bytes = BytesIO(f.read())
    >>> _salva_audio_do_video(video_bytes)
    "Continue"
    """
    with open(ARQUIVO_VIDEO_TEMP, mode='wb') as video_f:
        video_f.write(video_bytes.read())
    moviepy_video = VideoFileClip(str(ARQUIVO_VIDEO_TEMP))
    moviepy_video.audio.write_audiofile(str(ARQUIVO_AUDIO_TEMP))
    return "Continue"


@st.dialog("Enviar √°udio por v√≠deo mp4")
def transcreve_video_recebido():
    """
    Transcreve o √°udio de um v√≠deo enviado pelo usu√°rio.

    Opera√ß√µes:
    \n\t- Exibe um campo para entrada de um prompt opcional.
    \n\t- Permite o upload de um arquivo de v√≠deo no formato `.mp4`.
    \n\t- Salva o √°udio extra√≠do do v√≠deo temporariamente.
    \n\t- Envia o √°udio para transcri√ß√£o utilizando a API da OpenAI (Whisper-1).
    \n\t- Exibe a transcri√ß√£o resultante.

    Retorno:
    \n\t`None`: Apenas exibe a transcri√ß√£o do √°udio no Streamlit.

    Exemplo:
    >>> transcreve_video_recebido()
    """

    if st.session_state['api_key'] == '':
        st.error('Adicone uma chave de api na aba de configura√ß√µes')
    else:
        headers = {
            "Authorization": f"Bearer {st.session_state['api_key']}"
        }
        prompt_video = st.text_input(
            '(opcional) Sugest√£o para orientar a transcri√ß√£o.',
            key='input_video')
        st.info(
            "**Arraste e solte o arquivo no campo abaixo ou clique em 'Browse Files' para selecionar um arquivo.**")
        arquivo_video = st.file_uploader('Adicione um arquivo de v√≠deo .mp4', type=[
                                         'mp4'], label_visibility='collapsed')

        if arquivo_video is not None and st.session_state['transcricao'] == '':
            with st.spinner('Convertendo o v√≠deo para √°udio...'):
                flag_continue = _salva_audio_do_video(arquivo_video)

            if not flag_continue is None and st.session_state['transcricao'] == '':
                with st.spinner('Processando o √°udio...'):
                    st.info(
                        "Sua transcri√ß√£o est√° sendo preparada para ser enviada!")
                    transcreve_audio(ARQUIVO_AUDIO_TEMP,
                                     prompt_video, headers, False)
                    flag_continue = None
                    arquivo_video = None

                    with st.spinner('Processando a resposta...'):
                        nova_mensagem(st.session_state['transcricao'],
                                      st.session_state['mensagens'],
                                      False,
                                      None)
                        st.rerun()

    if st.button("Fechar", key="Fechar"):
        js_debug("Bot√£o Fechar")
        js_debug(st.session_state['transcricao'])
        arquivo_video = None
        st.session_state['transcricao'] = ''
        st.session_state['show_modal'] = False
        st.rerun()


# TRANSCREVE AUDIO =====================================

@st.dialog("Enviar √°udio por arquivo mp3")
def transcreve_audio_recebido():
    """
    Transcreve um arquivo de √°udio enviado pelo usu√°rio.

    Opera√ß√µes:
    \n\t- Exibe um campo para entrada de um prompt opcional.
    \n\t- Permite o upload de um arquivo de √°udio no formato `.mp3`.
    \n\t- Envia o √°udio para transcri√ß√£o utilizando a API da OpenAI (Whisper-1).
    \n\t- Exibe a transcri√ß√£o resultante ou uma mensagem de erro, se necess√°rio.

    Retorno:
    \n\t`None`: Apenas exibe a transcri√ß√£o do √°udio no Streamlit.

    Exemplo:
    >>> transcreve_audio_recebido()
    """
    if st.session_state['api_key'] == '':
        st.error('Adicone uma chave de api na aba de configura√ß√µes')
    else:
        headers = {
            "Authorization": f"Bearer {st.session_state['api_key']}"
        }
        prompt_input = st.text_input(
            '(opcional) Sugest√£o para orientar a transcri√ß√£o.',
            key='input_audio')
        st.info(
            "**Arraste e solte o arquivo no campo abaixo ou clique em 'Browse Files' para selecionar um arquivo.**")
        arquivo_audio = st.file_uploader('Adicione um arquivo de √°udio .mp3', type=[
            'mp3'], label_visibility='collapsed')

        if arquivo_audio is not None and st.session_state['transcricao'] == '':
            audio_bytes = arquivo_audio.read()

            files = {
                'file': ('audio.mp3', BytesIO(audio_bytes), 'audio/mpeg'),
                'model': (None, 'whisper-1'),
                'language': (None, 'pt'),
                'response_format': (None, 'text'),
                'prompt': (None, prompt_input)
            }
            with st.spinner('Processando o √°udio...'):
                response = requests.post(
                    "https://api.openai.com/v1/audio/transcriptions", headers=headers, files=files)

                try:
                    if response.status_code == 200:
                        st.info(
                            "Sua transcri√ß√£o est√° sendo preparada para ser enviada!")
                        transcricao = response.text
                        st.session_state['transcricao'] = transcricao
                        arquivo_audio = None

                        with st.spinner('Processando a resposta...'):
                            nova_mensagem(transcricao,
                                          st.session_state['mensagens'],
                                          False,
                                          None)
                            st.rerun()

                    else:
                        st.error(
                            f"Erro: {response.status_code} ao decodificar a resposta da API. Veja os detalhes no terminal.")
                        print(f"Erro: {response.status_code}")
                        print("Erro ao decodificar a resposta da API. Resposta:")
                        print(response.text)

                except ValueError:
                    st.error(
                        "Erro ao decodificar a resposta da API. Veja os detalhes no terminal.")
                    print(f"Erro: {response.status_code}")
                    print("Erro ao decodificar a resposta da API. Resposta:")
                    print(response.text)
                    st.write(response.status_code)

        if st.button("Fechar", key="Fechar"):
            js_debug("Bot√£o Fechar")
            js_debug(st.session_state['transcricao'])
            arquivo_audio = None
            st.session_state['transcricao'] = ''
            st.session_state['show_modal'] = False
            st.rerun()


def renderizar_mensagens(mensagens: list, placeholder=None) -> None:
    """
    Renderiza as mensagens da conversa na interface do Streamlit.

    Par√¢metros:
    \n\t`mensagens (list)`: Lista contendo as mensagens a serem exibidas.
    \n\t`placeholder`: Elemento opcional do Streamlit para atualiza√ß√£o din√¢mica.

    Retorno:
    \n\t`None`: Apenas exibe as mensagens na interface.

    Exemplo:
    >>> mensagens = [
    >>>     {"role": "user", "content": "Ol√°!"},
    >>>     {"role": "assistant", "content": "Oi! Como posso te ajudar?"}
    >>> ]
    >>> renderizar_mensagens(mensagens)
    """
    for mensagem in mensagens:
        if mensagem['role'] == 'user':
            chat = st.chat_message(mensagem['role'])
            chat.markdown(
                f'<div class="user-message">{mensagem["content"]}</div>', unsafe_allow_html=True)
        elif mensagem['role'] == 'assistant' and placeholder is None:
            chat = st.chat_message(mensagens['role'])
            chat.markdown(
                f'<div class="assistant-message">{mensagens["content"]}</div>', unsafe_allow_html=True)
        if placeholder is not None:
            placeholder.markdown(
                "<div class='assistant-message'>‚ñå</div>", unsafe_allow_html=True)


# P√ÅGINA PRINCIPAL ==================================================

def pg_conversas() -> None:
    """
    Exibe a interface principal do chat baseado em LLM (Large Language Model).

    Opera√ß√µes:
    \n\t- Exibe o cabe√ßalho do chat.
    \n\t- Carrega e renderiza as mensagens da conversa.
    \n\t- Exibe um campo de entrada de mensagens para intera√ß√£o do usu√°rio.
    \n\t- Permite a sele√ß√£o de diferentes formatos de entrada (texto, √°udio, v√≠deo).
    \n\t- Gerencia a l√≥gica de envio da mensagem e processamento da resposta.

    Retorno:
    \n\t`None`: Apenas exibe a interface e gerencia as intera√ß√µes no Streamlit.

    Exemplo:
    >>> pg_conversas()
    """
    st.header('üó®Ô∏è Chat de Conversas - LLM', divider=True)

    mensagens = ler_mensagens(st.session_state['mensagens'])

    placeholder = st.empty()

    for mensagem in mensagens:
        if mensagem['role'] == 'user':
            chat = st.chat_message(mensagem['role'])
            chat.markdown(
                f'<div class="user-message">{mensagem["content"]}</div>', unsafe_allow_html=True)
        else:
            chat = st.chat_message(mensagem['role'])
            chat.markdown(
                f'<div class="assistant-message">{mensagem["content"]}</div>', unsafe_allow_html=True)

    with st.container(key='footer'):
        prompt = st.chat_input('Fale com o tutor')

        options_pills = ["‚å®Ô∏è", "üé§", "üìΩÔ∏è"]

        seleciona_midia = st.pills(
            "Selecione a M√≠dia",
            options_pills,
            selection_mode="single",
            key='input-select',
            label_visibility="hidden"
        )

        st.session_state['input'] = seleciona_midia

        js_debug(st.session_state['input'])

        # Verificar a sele√ß√£o para abrir o di√°logo correspondente
        if st.session_state['input'] == "‚å®Ô∏è":
            js_debug("reinicia o modal")
            # reseta
            st.session_state['show_modal'] = True
            st.session_state['transcricao'] = ''
        elif st.session_state['input'] == "üé§" and st.session_state['show_modal']:
            js_debug("transcreve_audio_recebido()")
            st.session_state['input'] = "‚å®Ô∏è"
            transcreve_audio_recebido()
        elif st.session_state['input'] == "üìΩÔ∏è" and st.session_state['show_modal']:
            js_debug("transcreve_video_recebido()")
            st.session_state['input'] = "‚å®Ô∏è"
            transcreve_video_recebido()

        st.markdown(
            '_O Chat de Conversas pode cometer erros. Considere verificar informa√ß√µes importantes._')

        # Faz a requisi√ß√£o, se houver
        if prompt:
            if st.session_state['api_key'] == '':
                st.error('Adicone uma chave de api na aba de configura√ß√µes')
            else:
                nova_mensagem(prompt, mensagens, True, placeholder)


# P√°gina de Configura√ß√µes =========================

def config_page() -> None:
    """
    Exibe a p√°gina de configura√ß√µes do chatbot, permitindo modificar par√¢metros do modelo de IA.

    Opera√ß√µes:
    \n\t- Exibe os campos de entrada para altera√ß√£o do modelo de IA.
    \n\t- Permite modificar o tipo de busca e par√¢metros de recupera√ß√£o de informa√ß√µes.
    \n\t- Exibe e permite a edi√ß√£o do prompt base utilizado pelo chatbot.
    \n\t- Atualiza os valores na sess√£o do Streamlit e reinicia o chatbot se necess√°rio.

    Retorno:
    \n\t`None`: Apenas exibe a interface e atualiza os valores de configura√ß√£o no Streamlit.

    Exemplo:
    >>> config_page()
    """
    st.header('üìë - RAG Config', divider=True)

    model = st.text_input('Modifique o modelo',
                          value=get_config('modelo'))

    retrieval_search_type = st.text_input('Modifique o tipo de retrieval',
                                          value=get_config('retrieval_search_type'))

    retrieval_kwargs = st.text_input('Modifique os par√¢metros de retrieval',
                                     value=json.dumps(get_config('retrieval_kwargs')))

    prompt = st.text_area('Modifique o prompt padr√£o',
                          height=300,
                          value=get_config('prompt'))

    if st.button('Salvar par√¢metros', use_container_width=True):
        retrieval_kwargs = json.loads(retrieval_kwargs.replace("'", '"'))
        st.session_state['modelo'] = model
        st.session_state['retrieval_search_type'] = retrieval_search_type
        st.session_state['retrieval_kwargs'] = retrieval_kwargs
        st.session_state['prompt'] = prompt
        st.rerun()

    if st.button('Atualizar o ATI', use_container_width=True):
        if len(list(PASTA_ARQUIVOS.glob('*.pdf'))) == 0:
            st.error(
                'Adicione arquivos .pdf para inicializar o ATI (Agente Tutor Inteligente)')
        else:
            st.success('Inicializando o ATI (Agente Tutor Inteligente)...')
            cria_chain_conversa()
            st.rerun()


# P√°gina de Tutoria =========================

def pg_tutoria() -> None:
    """
    Exibe a p√°gina de tutoria do chatbot, permitindo intera√ß√µes com documentos previamente carregados.

    Opera√ß√µes:
    \n\t- Exibe um cabe√ßalho e um aviso se nenhum documento for carregado.
    \n\t- Recupera o hist√≥rico de conversas do chatbot e exibe as mensagens.
    \n\t- Permite ao usu√°rio interagir com o chatbot enviando novas mensagens.
    \n\t- Exibe respostas do chatbot com base nos documentos processados.

    Retorno:
    \n\t`None`: Apenas exibe a interface e processa as intera√ß√µes no Streamlit.

    Exemplo:
    >>> pg_tutoria()
    """
    st.header('üéì ATI - Agente Tutor Inteligente', divider=True)

    if not 'chain' in st.session_state or st.session_state['chain'] == '':
        st.error('Fa√ßa o upload de PDFs para come√ßar!')
    else:
        chain = st.session_state['chain']
        memory = chain.memory

        mensagens = memory.load_memory_variables({})['chat_history']

        container = st.container()
        for mensagem in mensagens:
            chat = container.chat_message(mensagem.type)
            chat.markdown(mensagem.content)

        nova_mensagem = st.chat_input(
            'Converse com o seu Agente Tutor Inteligente...')
        if nova_mensagem:
            chat = container.chat_message('human')
            chat.markdown(nova_mensagem)
            chat = container.chat_message('ai')
            chat.markdown('‚ñå ')  # Gerando resposta

            resposta = chain.invoke({'question': nova_mensagem})
            st.session_state['ultima_resposta'] = resposta
            st.rerun()


# P√°gina de An√°lise =========================

def pg_analise() -> None:
    """
    Exibe a p√°gina de an√°lise e depura√ß√£o das intera√ß√µes do chatbot.

    Opera√ß√µes:
    \n\t- Exibe um cabe√ßalho para a se√ß√£o de an√°lise.
    \n\t- Recupera a √∫ltima resposta gerada pelo chatbot.
    \n\t- Exibe o hist√≥rico de conversas e os documentos utilizados no contexto da resposta.
    \n\t- Mostra o prompt final gerado pelo modelo antes de processar a resposta.

    Retorno:
    \n\t`None`: Apenas exibe a interface e apresenta os detalhes da an√°lise.

    Exemplo:
    >>> pg_analise()
    """

    st.header('üìá P√°gina de debug', divider=True)

    prompt_template = get_config('prompt')
    prompt_template = PromptTemplate.from_template(prompt_template)

    if 'ultima_resposta' not in st.session_state or st.session_state['ultima_resposta'] == '':
        st.error('Realize uma pergunta para o modelo para visualizar o debug')
    else:
        ultima_resposta = st.session_state['ultima_resposta']

        contexto_docs = ultima_resposta['source_documents']
        contexto_list = [doc.page_content for doc in contexto_docs]
        contexto_str = '\n\n'.join(contexto_list)

        chain = st.session_state['chain']
        memory = chain.memory
        chat_history = memory.buffer_as_str

        with st.container(border=True):
            prompt = prompt_template.format(
                chat_history=chat_history,
                context=contexto_str,
                question=''
            )
            st.code(prompt)
